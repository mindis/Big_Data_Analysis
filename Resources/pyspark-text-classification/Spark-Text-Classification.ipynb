{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql import Row\n",
    "from pyspark.sql import SQLContext\n",
    "\n",
    "from pyspark.ml.linalg import Vector\n",
    "from pyspark.ml import Pipeline, PipelineModel\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.feature import HashingTF,StopWordsRemover,IDF,Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 31 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sc = SparkContext(\"local[2]\",\"Application\")\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents read in is: 2000\n",
      "Wall time: 2min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path=\"mini_newsgroups\\\\*\" #\"https://kdd.ics.uci.edu/databases/20newsgroups/mini_newsgroups.tar.gz\"\n",
    "newsGroupRowData=sc.wholeTextFiles(path)\n",
    "print \"Number of documents read in is:\",newsGroupRowData.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'file:/C:/Users/6910P/Documents/mini_newsgroups/sci.med/59627',\n",
       "  u'Newsgroups: sci.med\\nPath: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!sjha\\nFrom: sjha+@cs.cmu.edu (Somesh Jha)\\nSubject: What is intersection syndrome and Feldene?\\nMessage-ID: <C6EpA9.EFz.1@cs.cmu.edu>\\nSender: news@cs.cmu.edu (Usenet News System)\\nNntp-Posting-Host: gs73.sp.cs.cmu.edu\\nOrganization: School of Computer Science, Carnegie Mellon\\nDate: Sun, 2 May 1993 15:49:16 GMT\\nLines: 17\\n\\n\\nHi:\\n\\nI went to the orthopedist on Tuesday. He diagnosed me as having\\n\"intersection syndrome\". He prescribed Feldene for me. I want\\nto know more about the disease and the drug.\\n\\nThanks\\n\\n\\nSomesh\\n\\n\\n\\n\\n\\n\\n')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsGroupRowData.takeSample(False,1, 10L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'file:/C:/Users/6910P/Documents/mini_newsgroups/comp.sys.mac.hardware/52296', u'file:/C:/Users/6910P/Documents/mini_newsgroups/alt.atheism/53542', u'file:/C:/Users/6910P/Documents/mini_newsgroups/rec.autos/101592', u'file:/C:/Users/6910P/Documents/mini_newsgroups/rec.motorcycles/104430', u'file:/C:/Users/6910P/Documents/mini_newsgroups/rec.motorcycles/104302']\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "filepaths = newsGroupRowData.map(lambda (filepath, text): filepath)\n",
    "print filepaths.takeSample(False,5, 10L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Newsgroups: sci.med\\nPath: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!sjha\\nFrom: sjha+@cs.cmu.edu (Somesh Jha)\\nSubject: What is intersection syndrome and Feldene?\\nMessage-ID: <C6EpA9.EFz.1@cs.cmu.edu>\\nSender: news@cs.cmu.edu (Usenet News System)\\nNntp-Posting-Host: gs73.sp.cs.cmu.edu\\nOrganization: School of Computer Science, Carnegie Mellon\\nDate: Sun, 2 May 1993 15:49:16 GMT\\nLines: 17\\n\\n\\nHi:\\n\\nI went to the orthopedist on Tuesday. He diagnosed me as having\\n\"intersection syndrome\". He prescribed Feldene for me. I want\\nto know more about the disease and the drug.\\n\\nThanks\\n\\n\\nSomesh\\n\\n\\n\\n\\n\\n\\n']\n",
      "Wall time: 1min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "text = newsGroupRowData.map(lambda (filepath, text): text)\n",
    "print text.takeSample(False,1, 10L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'51121', u'51126', u'51127', u'51131', u'51139']\n",
      "Wall time: 1.64 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "id = filepaths.map(lambda filepath: filepath.split(\"/\")[-1])\n",
    "print id.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'alt.atheism', u'alt.atheism', u'alt.atheism', u'alt.atheism', u'alt.atheism']\n",
      "[u'sci.crypt', u'comp.sys.mac.hardware', u'sci.med', u'comp.windows.x', u'misc.forsale', u'talk.politics.guns', u'comp.os.ms-windows.misc', u'sci.space', u'rec.sport.baseball', u'rec.motorcycles', u'talk.politics.misc', u'soc.religion.christian', u'comp.graphics', u'talk.religion.misc', u'talk.politics.mideast', u'comp.sys.ibm.pc.hardware', u'alt.atheism', u'rec.sport.hockey', u'sci.electronics', u'rec.autos']\n",
      "Wall time: 37.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "topics = filepaths.map(lambda filepath: filepath.split(\"/\")[-2])\n",
    "print topics.take(5)\n",
    "print topics.distinct().take(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- topic: string (nullable = true)\n",
      "\n",
      "+-----+-----------+--------------------+\n",
      "|   id|      topic|                text|\n",
      "+-----+-----------+--------------------+\n",
      "|51121|alt.atheism|Xref: cantaloupe....|\n",
      "|51126|alt.atheism|Path: cantaloupe....|\n",
      "|51127|alt.atheism|Path: cantaloupe....|\n",
      "|51131|alt.atheism|Path: cantaloupe....|\n",
      "|51139|alt.atheism|Path: cantaloupe....|\n",
      "+-----+-----------+--------------------+\n",
      "\n",
      "Wall time: 23.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "# The schema is encoded in a string.\n",
    "schemaString = \"id text topic\"\n",
    "fields = [StructField(field_name, StringType(), True) for field_name in schemaString.split()]\n",
    "schema = StructType(fields)\n",
    "\n",
    "# Apply the schema to the RDD.\n",
    "newsgroups = newsGroupRowData.map(lambda (filepath, text): (filepath.split(\"/\")[-1],text,filepath.split(\"/\")[-2]))\n",
    "df = sqlContext.createDataFrame(newsgroups, schema)\n",
    "\n",
    "#print schema\n",
    "df.printSchema()\n",
    "\n",
    "# Creates a temporary view using the DataFrame\n",
    "df.createOrReplaceTempView(\"newsgroups\")\n",
    "\n",
    "# SQL can be run over DataFrames that have been registered as a table.\n",
    "results = sqlContext.sql(\"SELECT id,topic,text FROM newsgroups limit 5\")\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|               topic|cnt|\n",
      "+--------------------+---+\n",
      "|        misc.forsale|100|\n",
      "|      comp.windows.x|100|\n",
      "|    rec.sport.hockey|100|\n",
      "|  rec.sport.baseball|100|\n",
      "|comp.os.ms-window...|100|\n",
      "+--------------------+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = sqlContext.sql(\"select distinct topic, count(*) as cnt from newsgroups group by topic order by cnt desc limit 5\")\n",
    "results.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+\n",
      "|   id|                text|               topic|\n",
      "+-----+--------------------+--------------------+\n",
      "|38907|Path: cantaloupe....|       comp.graphics|\n",
      "|60691|Path: cantaloupe....|comp.sys.ibm.pc.h...|\n",
      "|51996|Path: cantaloupe....|comp.sys.mac.hard...|\n",
      "|38758|Xref: cantaloupe....|       comp.graphics|\n",
      "|38904|Xref: cantaloupe....|       comp.graphics|\n",
      "| 9622|Xref: cantaloupe....|comp.os.ms-window...|\n",
      "|67386|Path: cantaloupe....|      comp.windows.x|\n",
      "|52059|Xref: cantaloupe....|comp.sys.mac.hard...|\n",
      "|66400|Newsgroups: comp....|      comp.windows.x|\n",
      "|60841|Path: cantaloupe....|comp.sys.ibm.pc.h...|\n",
      "|10094|Path: cantaloupe....|comp.os.ms-window...|\n",
      "| 9911|Xref: cantaloupe....|comp.os.ms-window...|\n",
      "| 9943|Path: cantaloupe....|comp.os.ms-window...|\n",
      "|60992|Newsgroups: comp....|comp.sys.ibm.pc.h...|\n",
      "|52010|Path: cantaloupe....|comp.sys.mac.hard...|\n",
      "|38750|Path: cantaloupe....|       comp.graphics|\n",
      "| 9485|Xref: cantaloupe....|comp.os.ms-window...|\n",
      "| 9902|Newsgroups: comp....|comp.os.ms-window...|\n",
      "|61044|Path: cantaloupe....|comp.sys.ibm.pc.h...|\n",
      "|52190|Path: cantaloupe....|comp.sys.mac.hard...|\n",
      "+-----+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "Wall time: 35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_list = df[df.topic.like(\"comp%\")].collect()\n",
    "new_df = sc.parallelize(result_list).toDF()\n",
    "new_df.dropDuplicates().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+-----+\n",
      "|   id|                text|               topic|label|\n",
      "+-----+--------------------+--------------------+-----+\n",
      "|68232|Newsgroups: comp....|      comp.windows.x|  1.0|\n",
      "|14989|Path: cantaloupe....|           sci.crypt|  0.0|\n",
      "|15248|Xref: cantaloupe....|           sci.crypt|  0.0|\n",
      "|15736|Path: cantaloupe....|           sci.crypt|  0.0|\n",
      "|20738|Path: cantaloupe....|soc.religion.chri...|  0.0|\n",
      "+-----+--------------------+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labeledNewsGroups = df.withColumn(\"label\",df.topic.like(\"comp%\").cast(\"double\"))\n",
    "labeledNewsGroups.sample(False,0.003,10L).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total document count: 2000\n",
      "Training-set count: 1779\n",
      "Test-set count: 221\n"
     ]
    }
   ],
   "source": [
    "train_set, test_set = labeledNewsGroups.randomSplit([0.9, 0.1], 12345)\n",
    "print \"Total document count:\",labeledNewsGroups.count()\n",
    "print \"Training-set count:\",train_set.count()\n",
    "print \"Test-set count:\",test_set.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer().setInputCol(\"text\").setOutputCol(\"words\")\n",
    "remover= StopWordsRemover().setInputCol(\"words\").setOutputCol(\"filtered\").setCaseSensitive(False)\n",
    "hashingTF = HashingTF().setNumFeatures(1000).setInputCol(\"filtered\").setOutputCol(\"rawFeatures\")\n",
    "idf = IDF().setInputCol(\"rawFeatures\").setOutputCol(\"features\").setMinDocFreq(0)\n",
    "lr = LogisticRegression().setRegParam(0.01).setThreshold(0.5)\n",
    "pipeline=Pipeline(stages=[tokenizer,remover,hashingTF,idf, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression features column= features\n",
      "logistic regression label column= label\n",
      "Logistic regression threshold= 0.5\n"
     ]
    }
   ],
   "source": [
    "print \"Logistic regression features column=\",lr.getFeaturesCol()\n",
    "print \"logistic regression label column=\",lr.getLabelCol()\n",
    "print \"Logistic regression threshold=\",lr.getThreshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer:\n",
      "inputCol: input column name. (current: text)\n",
      "outputCol: output column name. (default: Tokenizer_4ba4b599d3828120d9e0__output, current: words)\n",
      "***************************\n",
      "Remover:\n",
      "caseSensitive: whether to do a case sensitive comparison over the stop words (default: False, current: False)\n",
      "inputCol: input column name. (current: words)\n",
      "outputCol: output column name. (default: StopWordsRemover_41a2b4f9d66ae347ce42__output, current: filtered)\n",
      "stopWords: The words to be filtered out (default: [u'i', u'me', u'my', u'myself', u'we', u'our', u'ours', u'ourselves', u'you', u'your', u'yours', u'yourself', u'yourselves', u'he', u'him', u'his', u'himself', u'she', u'her', u'hers', u'herself', u'it', u'its', u'itself', u'they', u'them', u'their', u'theirs', u'themselves', u'what', u'which', u'who', u'whom', u'this', u'that', u'these', u'those', u'am', u'is', u'are', u'was', u'were', u'be', u'been', u'being', u'have', u'has', u'had', u'having', u'do', u'does', u'did', u'doing', u'a', u'an', u'the', u'and', u'but', u'if', u'or', u'because', u'as', u'until', u'while', u'of', u'at', u'by', u'for', u'with', u'about', u'against', u'between', u'into', u'through', u'during', u'before', u'after', u'above', u'below', u'to', u'from', u'up', u'down', u'in', u'out', u'on', u'off', u'over', u'under', u'again', u'further', u'then', u'once', u'here', u'there', u'when', u'where', u'why', u'how', u'all', u'any', u'both', u'each', u'few', u'more', u'most', u'other', u'some', u'such', u'no', u'nor', u'not', u'only', u'own', u'same', u'so', u'than', u'too', u'very', u's', u't', u'can', u'will', u'just', u'don', u'should', u'now', u'd', u'll', u'm', u'o', u're', u've', u'y', u'ain', u'aren', u'couldn', u'didn', u'doesn', u'hadn', u'hasn', u'haven', u'isn', u'ma', u'mightn', u'mustn', u'needn', u'shan', u'shouldn', u'wasn', u'weren', u'won', u'wouldn'])\n",
      "***************************\n",
      "HashingTF:\n",
      "binary: If True, all non zero counts are set to 1. This is useful for discrete probabilistic models that model binary events rather than integer counts. Default False. (default: False)\n",
      "inputCol: input column name. (current: filtered)\n",
      "numFeatures: number of features. (default: 262144, current: 1000)\n",
      "outputCol: output column name. (default: HashingTF_483cb1d8c9fef73023bb__output, current: rawFeatures)\n",
      "***************************\n",
      "IDF:\n",
      "inputCol: input column name. (current: rawFeatures)\n",
      "minDocFreq: minimum number of documents in which a term should appear for filtering (default: 0, current: 0)\n",
      "outputCol: output column name. (default: IDF_4c738173123a94964191__output, current: features)\n",
      "***************************\n",
      "LogisticRegression:\n",
      "aggregationDepth: suggested depth for treeAggregate (>= 2). (default: 2)\n",
      "elasticNetParam: the ElasticNet mixing parameter, in range [0, 1]. For alpha = 0, the penalty is an L2 penalty. For alpha = 1, it is an L1 penalty. (default: 0.0)\n",
      "family: The name of family which is a description of the label distribution to be used in the model. Supported options: auto, binomial, multinomial (default: auto)\n",
      "featuresCol: features column name. (default: features)\n",
      "fitIntercept: whether to fit an intercept term. (default: True)\n",
      "labelCol: label column name. (default: label)\n",
      "maxIter: max number of iterations (>= 0). (default: 100)\n",
      "predictionCol: prediction column name. (default: prediction)\n",
      "probabilityCol: Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities. (default: probability)\n",
      "rawPredictionCol: raw prediction (a.k.a. confidence) column name. (default: rawPrediction)\n",
      "regParam: regularization parameter (>= 0). (default: 0.0, current: 0.01)\n",
      "standardization: whether to standardize the training features before fitting the model. (default: True)\n",
      "threshold: Threshold in binary classification prediction, in range [0, 1]. If threshold and thresholds are both set, they must match.e.g. if threshold is p, then thresholds must be equal to [1-p, p]. (default: 0.5, current: 0.5)\n",
      "thresholds: Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values > 0, excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class's threshold. (undefined)\n",
      "tol: the convergence tolerance for iterative algorithms (>= 0). (default: 1e-06)\n",
      "weightCol: weight column name. If this is not set or empty, we treat all instance weights as 1.0. (undefined)\n",
      "***************************\n",
      "Pipeline:\n",
      "stages: a list of pipeline stages (current: [Tokenizer_4ba4b599d3828120d9e0, StopWordsRemover_41a2b4f9d66ae347ce42, HashingTF_483cb1d8c9fef73023bb, IDF_4c738173123a94964191, LogisticRegression_491d9cbb20c32db6c100])\n"
     ]
    }
   ],
   "source": [
    "print \"Tokenizer:\"\n",
    "print tokenizer.explainParams()\n",
    "print \"***************************\"\n",
    "print \"Remover:\"\n",
    "print remover.explainParams()\n",
    "print \"***************************\"\n",
    "print \"HashingTF:\"\n",
    "print hashingTF.explainParams()\n",
    "print \"***************************\"\n",
    "print \"IDF:\"\n",
    "print idf.explainParams()\n",
    "print \"***************************\"\n",
    "print \"LogisticRegression:\"\n",
    "print lr.explainParams()\n",
    "print \"***************************\"\n",
    "print \"Pipeline:\"\n",
    "print pipeline.explainParams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'i',\n",
       " u'me',\n",
       " u'my',\n",
       " u'myself',\n",
       " u'we',\n",
       " u'our',\n",
       " u'ours',\n",
       " u'ourselves',\n",
       " u'you',\n",
       " u'your',\n",
       " u'yours',\n",
       " u'yourself',\n",
       " u'yourselves',\n",
       " u'he',\n",
       " u'him',\n",
       " u'his',\n",
       " u'himself',\n",
       " u'she',\n",
       " u'her',\n",
       " u'hers',\n",
       " u'herself',\n",
       " u'it',\n",
       " u'its',\n",
       " u'itself',\n",
       " u'they',\n",
       " u'them',\n",
       " u'their',\n",
       " u'theirs',\n",
       " u'themselves',\n",
       " u'what',\n",
       " u'which',\n",
       " u'who',\n",
       " u'whom',\n",
       " u'this',\n",
       " u'that',\n",
       " u'these',\n",
       " u'those',\n",
       " u'am',\n",
       " u'is',\n",
       " u'are',\n",
       " u'was',\n",
       " u'were',\n",
       " u'be',\n",
       " u'been',\n",
       " u'being',\n",
       " u'have',\n",
       " u'has',\n",
       " u'had',\n",
       " u'having',\n",
       " u'do',\n",
       " u'does',\n",
       " u'did',\n",
       " u'doing',\n",
       " u'a',\n",
       " u'an',\n",
       " u'the',\n",
       " u'and',\n",
       " u'but',\n",
       " u'if',\n",
       " u'or',\n",
       " u'because',\n",
       " u'as',\n",
       " u'until',\n",
       " u'while',\n",
       " u'of',\n",
       " u'at',\n",
       " u'by',\n",
       " u'for',\n",
       " u'with',\n",
       " u'about',\n",
       " u'against',\n",
       " u'between',\n",
       " u'into',\n",
       " u'through',\n",
       " u'during',\n",
       " u'before',\n",
       " u'after',\n",
       " u'above',\n",
       " u'below',\n",
       " u'to',\n",
       " u'from',\n",
       " u'up',\n",
       " u'down',\n",
       " u'in',\n",
       " u'out',\n",
       " u'on',\n",
       " u'off',\n",
       " u'over',\n",
       " u'under',\n",
       " u'again',\n",
       " u'further',\n",
       " u'then',\n",
       " u'once',\n",
       " u'here',\n",
       " u'there',\n",
       " u'when',\n",
       " u'where',\n",
       " u'why',\n",
       " u'how',\n",
       " u'all',\n",
       " u'any',\n",
       " u'both',\n",
       " u'each',\n",
       " u'few',\n",
       " u'more',\n",
       " u'most',\n",
       " u'other',\n",
       " u'some',\n",
       " u'such',\n",
       " u'no',\n",
       " u'nor',\n",
       " u'not',\n",
       " u'only',\n",
       " u'own',\n",
       " u'same',\n",
       " u'so',\n",
       " u'than',\n",
       " u'too',\n",
       " u'very',\n",
       " u's',\n",
       " u't',\n",
       " u'can',\n",
       " u'will',\n",
       " u'just',\n",
       " u'don',\n",
       " u'should',\n",
       " u'now',\n",
       " u'd',\n",
       " u'll',\n",
       " u'm',\n",
       " u'o',\n",
       " u're',\n",
       " u've',\n",
       " u'y',\n",
       " u'ain',\n",
       " u'aren',\n",
       " u'couldn',\n",
       " u'didn',\n",
       " u'doesn',\n",
       " u'hadn',\n",
       " u'hasn',\n",
       " u'haven',\n",
       " u'isn',\n",
       " u'ma',\n",
       " u'mightn',\n",
       " u'mustn',\n",
       " u'needn',\n",
       " u'shan',\n",
       " u'shouldn',\n",
       " u'wasn',\n",
       " u'weren',\n",
       " u'won',\n",
       " u'wouldn']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remover.getStopWords()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model=pipeline.fit(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+----------+-----+\n",
      "|   id|               topic|         probability|prediction|label|\n",
      "+-----+--------------------+--------------------+----------+-----+\n",
      "|51186|         alt.atheism|[0.99545605647335...|       0.0|  0.0|\n",
      "|53459|         alt.atheism|[0.99656409133350...|       0.0|  0.0|\n",
      "| 9942|comp.os.ms-window...|[0.89795237438370...|       0.0|  1.0|\n",
      "|20866|soc.religion.chri...|[0.98273679010727...|       0.0|  0.0|\n",
      "|54633|  talk.politics.guns|[0.47279161297191...|       1.0|  0.0|\n",
      "+-----+--------------------+--------------------+----------+-----+\n",
      "\n",
      "+-----+--------------------+--------------------+----------+-----+\n",
      "|   id|               topic|         probability|prediction|label|\n",
      "+-----+--------------------+--------------------+----------+-----+\n",
      "|38271|       comp.graphics|[0.02780255772952...|       1.0|  1.0|\n",
      "|50473|comp.sys.mac.hard...|[0.14943992966858...|       1.0|  1.0|\n",
      "|60699|comp.sys.ibm.pc.h...|[0.18058644545815...|       1.0|  1.0|\n",
      "| 9667|comp.os.ms-window...|[0.14142114961665...|       1.0|  1.0|\n",
      "+-----+--------------------+--------------------+----------+-----+\n",
      "\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "predictions = model.transform(test_set)\n",
    "predictions.select(\"id\",\"topic\",\"probability\",\"prediction\",\"label\").sample(False,0.01,10L).show(5)\n",
    "predictions.select(\"id\",\"topic\",\"probability\",\"prediction\",\"label\").filter(predictions.topic.like(\"comp%\")).sample(False,0.1,10L).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|   id|                text|               topic|label|               words|            filtered|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
      "+-----+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "|51186|Path: cantaloupe....|         alt.atheism|  0.0|[path:, cantaloup...|[path:, cantaloup...|(1000,[19,23,37,4...|(1000,[19,23,37,4...|[5.38940572713749...|[0.99545605647335...|       0.0|\n",
      "|53459|Newsgroups: alt.a...|         alt.atheism|  0.0|[newsgroups:, alt...|[newsgroups:, alt...|(1000,[1,9,17,25,...|(1000,[1,9,17,25,...|[5.67003203160359...|[0.99656409133350...|       0.0|\n",
      "| 9942|Xref: cantaloupe....|comp.os.ms-window...|  1.0|[xref:, cantaloup...|[xref:, cantaloup...|(1000,[4,8,20,25,...|(1000,[4,8,20,25,...|[2.17467740956945...|[0.89795237438370...|       0.0|\n",
      "|20866|Path: cantaloupe....|soc.religion.chri...|  0.0|[path:, cantaloup...|[path:, cantaloup...|(1000,[12,25,27,3...|(1000,[12,25,27,3...|[4.04176368115652...|[0.98273679010727...|       0.0|\n",
      "|54633|Newsgroups: talk....|  talk.politics.guns|  0.0|[newsgroups:, tal...|[newsgroups:, tal...|(1000,[8,91,96,97...|(1000,[8,91,96,97...|[-0.1089411648151...|[0.47279161297191...|       1.0|\n",
      "+-----+--------------------+--------------------+-----+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.sample(False,0.01,10L).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area under ROC curve: 0.909709144172\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator().setMetricName(\"areaUnderROC\")\n",
    "print \"Area under ROC curve:\",evaluator.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(hashingTF.numFeatures,[1000,10000,100000])\\\n",
    "    .addGrid(idf.minDocFreq,[0,10,100])\\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv = CrossValidator().setEstimator(pipeline).setEvaluator(evaluator).setEstimatorParamMaps(paramGrid).setNumFolds(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'list'>\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cvModel = cv.fit(train_set)\n",
    "print \"Area under the ROC curve for best fitted model =\",evaluator.evaluate(cvModel.transform(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Area under ROC curve for non-tuned model: 0.909709144172\n",
      "Area under ROC curve for fitted model: 0.96578782172\n"
     ]
    }
   ],
   "source": [
    "print \"Area under ROC curve for non-tuned model:\",evaluator.evaluate(predictions)\n",
    "print \"Area under ROC curve for fitted model:\",evaluator.evaluate(cvModel.transform(test_set))\n",
    "#print \"Improvement:%.2f\".format(evaluator.evaluate(cvModel.transform(test_set)) - evaluator.evaluate(predictions))*100 / evaluator.evaluate(predictions)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
