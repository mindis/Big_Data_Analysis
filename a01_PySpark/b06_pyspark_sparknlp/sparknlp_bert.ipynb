{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Load-the-libraries\" data-toc-modified-id=\"Load-the-libraries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load the libraries</a></span></li><li><span><a href=\"#Useful-Functions\" data-toc-modified-id=\"Useful-Functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Useful Functions</a></span></li><li><span><a href=\"#Load-the-data\" data-toc-modified-id=\"Load-the-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load the data</a></span></li><li><span><a href=\"#Sparknlp-functions\" data-toc-modified-id=\"Sparknlp-functions-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Sparknlp functions</a></span></li><li><span><a href=\"#Bert-using-sparknlp\" data-toc-modified-id=\"Bert-using-sparknlp-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Bert using sparknlp</a></span></li><li><span><a href=\"#Modelling:-logistic-regression\" data-toc-modified-id=\"Modelling:-logistic-regression-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Modelling: logistic regression</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:02:21.381158Z",
     "start_time": "2020-09-09T00:02:21.376876Z"
    }
   },
   "outputs": [],
   "source": [
    "#=============== setup sparknlp\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/Users/poudel/opt/miniconda3/envs/mysparknlp/lib/python3.7/site-packages\")\n",
    "os.environ[\"SPARK_HOME\"] = \"/Users/poudel/Softwares/Spark/spark-2.4.4-bin-hadoop2.7\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/Users/poudel/opt/miniconda3/envs/mysparknlp/bin/python\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"jupyter\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"] = \"notebook\"\n",
    "#================ setup sparknlp end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:08:37.381301Z",
     "start_time": "2020-09-09T00:08:35.351744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('numpy', '1.19.1'), ('pandas', '0.23.4'), ('seaborn', '0.10.1')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('max_columns',100)\n",
    "\n",
    "import time,os,json\n",
    "time_start_notebook = time.time()\n",
    "home = os.path.expanduser('~')\n",
    "SEED=100\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "[(x.__name__,x.__version__) for x in [np,pd,sns]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:00:58.569724Z",
     "start_time": "2020-09-09T01:00:58.545260Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_methods(obj, ncols=7,\n",
    "            start=None, inside=None,exclude=None,\n",
    "            caps_only=False,lower_only=False,\n",
    "                            printt=False):\n",
    "    \"\"\" Show all the attributes of a given method.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    obj: object\n",
    "        Name of python object. eg. list, pd.DataFrame\n",
    "    ncols: int\n",
    "        Number of columns\n",
    "    start: str\n",
    "        Substring the attribute starsts with.\n",
    "    inside: str or tuple or list\n",
    "        Show only these attributes if given substring exists.\n",
    "    exclude: str or tuple or list\n",
    "        Exclude these exact elements\n",
    "    caps_only: bool\n",
    "        Show only Title case words\n",
    "    lower_only: bool\n",
    "        Show only lowercase case words\n",
    "    printt: bool\n",
    "        Print the dataframe or not.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # print(f'Object Type: {type(obj)}\\n')\n",
    "    lst = [I for I in dir(obj) if I[0]!='_' ]\n",
    "\n",
    "    # exclude usual imports\n",
    "    usual_imports = ['np','pd','os','sys','time','psycopg2',\n",
    "                    'plt','string','px',\n",
    "                    're','nltk','sklearn','spacy']\n",
    "    lst = [I for I in lst\n",
    "            if I not in usual_imports ]\n",
    "\n",
    "    # capital only (for classes)\n",
    "    if caps_only:\n",
    "        lst = [I for I in lst if I[0].isupper()]\n",
    "\n",
    "    # lowercase only (method attributes)\n",
    "    if lower_only:\n",
    "        lst = [I for I in lst if I[0].islower()]\n",
    "\n",
    "    # starts with something\n",
    "    if isinstance(start,str):\n",
    "        lst = [I for I in lst if i.startswith(start)]\n",
    "\n",
    "    if isinstance(start,tuple) or isinstance(start,list):\n",
    "        lst = [I for I in lst for start_i in start\n",
    "                if i.startswith(start_i)]\n",
    "\n",
    "    # inside something\n",
    "    if isinstance(inside,str):\n",
    "        lst = [I for I in lst if inside in I]\n",
    "    if isinstance(inside,tuple) or isinstance(inside,list):\n",
    "        lst = [I for I in lst for inside_i in inside\n",
    "                if inside_i in I]\n",
    "\n",
    "    # exclude substring\n",
    "    if isinstance(exclude,str):\n",
    "        lst = [I for I in lst if I != exclude]\n",
    "\n",
    "    if isinstance(exclude,tuple) or isinstance(exclude,list):\n",
    "        lst = [I for I in lst if I not in exclude]\n",
    "\n",
    "    # ouput dataframe\n",
    "    df = pd.DataFrame(np.array_split(lst,ncols)).T.fillna('')\n",
    "\n",
    "    # for terminal sometimes we need to print\n",
    "    if printt:\n",
    "        print(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:02:36.923057Z",
     "start_time": "2020-09-09T00:02:22.206838Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|                text|label|\n",
      "+--------------------+-----+\n",
      "|New York is the g...|    0|\n",
      "|The beauty of Par...|    1|\n",
      "|The Centre Pompid...|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "\n",
    "spark = sparknlp.start()\n",
    "data = [\n",
    "  (\"New York is the greatest city in the world\", 0),\n",
    "  (\"The beauty of Paris is vast\", 1),\n",
    "  (\"The Centre Pompidou is in Paris\", 1)\n",
    "]\n",
    "\n",
    "sdf = spark.createDataFrame(data, [\"text\",\"label\"])\n",
    "sdf.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparknlp functions\n",
    "sparknlp Annotators: https://nlp.johnsnowlabs.com/docs/en/annotators#documentassembler-getting-data-in  \n",
    "sparknlp models: https://nlp.johnsnowlabs.com/docs/en/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:01:21.496106Z",
     "start_time": "2020-09-09T01:01:21.481679Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunk2Doc</td>\n",
       "      <td>Finisher</td>\n",
       "      <td>annotation</td>\n",
       "      <td>annotators</td>\n",
       "      <td>common</td>\n",
       "      <td>internal</td>\n",
       "      <td>start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doc2Chunk</td>\n",
       "      <td>SparkSession</td>\n",
       "      <td>annotator</td>\n",
       "      <td>base</td>\n",
       "      <td>embeddings</td>\n",
       "      <td>pretrained</td>\n",
       "      <td>version</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DocumentAssembler</td>\n",
       "      <td>TokenAssembler</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0               1           2           3           4  \\\n",
       "0          Chunk2Doc        Finisher  annotation  annotators      common   \n",
       "1          Doc2Chunk    SparkSession   annotator        base  embeddings   \n",
       "2  DocumentAssembler  TokenAssembler                                       \n",
       "\n",
       "            5        6  \n",
       "0    internal    start  \n",
       "1  pretrained  version  \n",
       "2                       "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_methods(sparknlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:01:32.743368Z",
     "start_time": "2020-09-09T01:01:32.729868Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABC</td>\n",
       "      <td>Finisher</td>\n",
       "      <td>RecursiveEstimator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Annotation</td>\n",
       "      <td>HasRecursiveFit</td>\n",
       "      <td>RecursivePipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AnnotatorProperties</td>\n",
       "      <td>HasRecursiveTransform</td>\n",
       "      <td>RecursivePipelineModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AnnotatorTransformer</td>\n",
       "      <td>JavaEstimator</td>\n",
       "      <td>RecursiveTransformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk2Doc</td>\n",
       "      <td>LightPipeline</td>\n",
       "      <td>TokenAssembler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Doc2Chunk</td>\n",
       "      <td>Param</td>\n",
       "      <td>Transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DocumentAssembler</td>\n",
       "      <td>Params</td>\n",
       "      <td>TypeConverters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EmbeddingsFinisher</td>\n",
       "      <td>Pipeline</td>\n",
       "      <td>keyword_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Estimator</td>\n",
       "      <td>PipelineModel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0                      1                       2\n",
       "0                   ABC               Finisher      RecursiveEstimator\n",
       "1            Annotation        HasRecursiveFit       RecursivePipeline\n",
       "2   AnnotatorProperties  HasRecursiveTransform  RecursivePipelineModel\n",
       "3  AnnotatorTransformer          JavaEstimator    RecursiveTransformer\n",
       "4             Chunk2Doc          LightPipeline          TokenAssembler\n",
       "5             Doc2Chunk                  Param             Transformer\n",
       "6     DocumentAssembler                 Params          TypeConverters\n",
       "7    EmbeddingsFinisher               Pipeline            keyword_only\n",
       "8             Estimator          PipelineModel                        "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_methods(sparknlp.base,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:01:44.141589Z",
     "start_time": "2020-09-09T01:01:44.098673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AlbertEmbeddings</td>\n",
       "      <td>NGramGenerator</td>\n",
       "      <td>Tokenizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AnnotatorApproach</td>\n",
       "      <td>NerApproach</td>\n",
       "      <td>TokenizerModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AnnotatorModel</td>\n",
       "      <td>NerConverter</td>\n",
       "      <td>TypeConverters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AnnotatorProperties</td>\n",
       "      <td>NerCrfApproach</td>\n",
       "      <td>TypedDependencyParserApproach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BertEmbeddings</td>\n",
       "      <td>NerCrfModel</td>\n",
       "      <td>TypedDependencyParserModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BertSentenceEmbeddings</td>\n",
       "      <td>NerDLApproach</td>\n",
       "      <td>UniversalSentenceEncoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BigTextMatcher</td>\n",
       "      <td>NerDLModel</td>\n",
       "      <td>ViveknSentimentApproach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BigTextMatcherModel</td>\n",
       "      <td>NerOverwriter</td>\n",
       "      <td>ViveknSentimentModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ChunkEmbeddings</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>WordEmbeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ChunkTokenizer</td>\n",
       "      <td>NormalizerModel</td>\n",
       "      <td>WordEmbeddingsModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ChunkTokenizerModel</td>\n",
       "      <td>NorvigSweetingApproach</td>\n",
       "      <td>XlnetEmbeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunker</td>\n",
       "      <td>NorvigSweetingModel</td>\n",
       "      <td>YakeModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ClassifierDLApproach</td>\n",
       "      <td>Param</td>\n",
       "      <td>annotators</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ClassifierDLModel</td>\n",
       "      <td>Params</td>\n",
       "      <td>classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ContextSpellCheckerApproach</td>\n",
       "      <td>PerceptronApproach</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ContextSpellCheckerModel</td>\n",
       "      <td>PerceptronModel</td>\n",
       "      <td>context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CoverageResult</td>\n",
       "      <td>ReadAs</td>\n",
       "      <td>crf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DateMatcher</td>\n",
       "      <td>RecursiveAnnotatorApproach</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DateMatcherUtils</td>\n",
       "      <td>RecursiveTokenizer</td>\n",
       "      <td>dep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DeepSentenceDetector</td>\n",
       "      <td>RecursiveTokenizerModel</td>\n",
       "      <td>dl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DependencyParserApproach</td>\n",
       "      <td>RegexMatcher</td>\n",
       "      <td>embeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DependencyParserModel</td>\n",
       "      <td>RegexMatcherModel</td>\n",
       "      <td>keyword</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ElmoEmbeddings</td>\n",
       "      <td>RegexRule</td>\n",
       "      <td>keyword_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ExternalResource</td>\n",
       "      <td>RegexTokenizer</td>\n",
       "      <td>ld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HasCaseSensitiveProperties</td>\n",
       "      <td>SentenceDetector</td>\n",
       "      <td>ner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>HasEmbeddingsProperties</td>\n",
       "      <td>SentenceDetectorParams</td>\n",
       "      <td>norvig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HasExcludableStorage</td>\n",
       "      <td>SentenceEmbeddings</td>\n",
       "      <td>parser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>HasStorage</td>\n",
       "      <td>SentimentDLApproach</td>\n",
       "      <td>perceptron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>HasStorageModel</td>\n",
       "      <td>SentimentDLModel</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>HasStorageRef</td>\n",
       "      <td>SentimentDetector</td>\n",
       "      <td>pragmatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>JavaEstimator</td>\n",
       "      <td>SentimentDetectorModel</td>\n",
       "      <td>regex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>JavaMLWritable</td>\n",
       "      <td>Stemmer</td>\n",
       "      <td>sbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>JavaModel</td>\n",
       "      <td>StopWordsCleaner</td>\n",
       "      <td>sda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LanguageDetectorDL</td>\n",
       "      <td>SymmetricDeleteApproach</td>\n",
       "      <td>spell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lemmatizer</td>\n",
       "      <td>SymmetricDeleteModel</td>\n",
       "      <td>symmetric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LemmatizerModel</td>\n",
       "      <td>TextMatcher</td>\n",
       "      <td>typdep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>MultiClassifierDLApproach</td>\n",
       "      <td>TextMatcherModel</td>\n",
       "      <td>vivekn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>MultiClassifierDLModel</td>\n",
       "      <td>Token2Chunk</td>\n",
       "      <td>yake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>MultiDateMatcher</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0                           1  \\\n",
       "0              AlbertEmbeddings              NGramGenerator   \n",
       "1             AnnotatorApproach                 NerApproach   \n",
       "2                AnnotatorModel                NerConverter   \n",
       "3           AnnotatorProperties              NerCrfApproach   \n",
       "4                BertEmbeddings                 NerCrfModel   \n",
       "5        BertSentenceEmbeddings               NerDLApproach   \n",
       "6                BigTextMatcher                  NerDLModel   \n",
       "7           BigTextMatcherModel               NerOverwriter   \n",
       "8               ChunkEmbeddings                  Normalizer   \n",
       "9                ChunkTokenizer             NormalizerModel   \n",
       "10          ChunkTokenizerModel      NorvigSweetingApproach   \n",
       "11                      Chunker         NorvigSweetingModel   \n",
       "12         ClassifierDLApproach                       Param   \n",
       "13            ClassifierDLModel                      Params   \n",
       "14  ContextSpellCheckerApproach          PerceptronApproach   \n",
       "15     ContextSpellCheckerModel             PerceptronModel   \n",
       "16               CoverageResult                      ReadAs   \n",
       "17                  DateMatcher  RecursiveAnnotatorApproach   \n",
       "18             DateMatcherUtils          RecursiveTokenizer   \n",
       "19         DeepSentenceDetector     RecursiveTokenizerModel   \n",
       "20     DependencyParserApproach                RegexMatcher   \n",
       "21        DependencyParserModel           RegexMatcherModel   \n",
       "22               ElmoEmbeddings                   RegexRule   \n",
       "23             ExternalResource              RegexTokenizer   \n",
       "24   HasCaseSensitiveProperties            SentenceDetector   \n",
       "25      HasEmbeddingsProperties      SentenceDetectorParams   \n",
       "26         HasExcludableStorage          SentenceEmbeddings   \n",
       "27                   HasStorage         SentimentDLApproach   \n",
       "28              HasStorageModel            SentimentDLModel   \n",
       "29                HasStorageRef           SentimentDetector   \n",
       "30                JavaEstimator      SentimentDetectorModel   \n",
       "31               JavaMLWritable                     Stemmer   \n",
       "32                    JavaModel            StopWordsCleaner   \n",
       "33           LanguageDetectorDL     SymmetricDeleteApproach   \n",
       "34                   Lemmatizer        SymmetricDeleteModel   \n",
       "35              LemmatizerModel                 TextMatcher   \n",
       "36    MultiClassifierDLApproach            TextMatcherModel   \n",
       "37       MultiClassifierDLModel                 Token2Chunk   \n",
       "38             MultiDateMatcher                               \n",
       "\n",
       "                                2  \n",
       "0                       Tokenizer  \n",
       "1                  TokenizerModel  \n",
       "2                  TypeConverters  \n",
       "3   TypedDependencyParserApproach  \n",
       "4      TypedDependencyParserModel  \n",
       "5        UniversalSentenceEncoder  \n",
       "6         ViveknSentimentApproach  \n",
       "7            ViveknSentimentModel  \n",
       "8                  WordEmbeddings  \n",
       "9             WordEmbeddingsModel  \n",
       "10                XlnetEmbeddings  \n",
       "11                      YakeModel  \n",
       "12                     annotators  \n",
       "13                     classifier  \n",
       "14                            com  \n",
       "15                        context  \n",
       "16                            crf  \n",
       "17                           deep  \n",
       "18                            dep  \n",
       "19                             dl  \n",
       "20                     embeddings  \n",
       "21                        keyword  \n",
       "22                   keyword_only  \n",
       "23                             ld  \n",
       "24                            ner  \n",
       "25                         norvig  \n",
       "26                         parser  \n",
       "27                     perceptron  \n",
       "28                            pos  \n",
       "29                      pragmatic  \n",
       "30                          regex  \n",
       "31                            sbd  \n",
       "32                            sda  \n",
       "33                          spell  \n",
       "34                      symmetric  \n",
       "35                         typdep  \n",
       "36                         vivekn  \n",
       "37                           yake  \n",
       "38                                 "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_methods(sparknlp.annotator,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:01:55.173283Z",
     "start_time": "2020-09-09T01:01:55.160708Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AnnotatorApproach</td>\n",
       "      <td>HasExcludableStorage</td>\n",
       "      <td>Param</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AnnotatorModel</td>\n",
       "      <td>HasStorage</td>\n",
       "      <td>Params</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AnnotatorProperties</td>\n",
       "      <td>HasStorageModel</td>\n",
       "      <td>ReadAs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CoverageResult</td>\n",
       "      <td>HasStorageRef</td>\n",
       "      <td>RecursiveAnnotatorApproach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExternalResource</td>\n",
       "      <td>JavaEstimator</td>\n",
       "      <td>RegexRule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HasCaseSensitiveProperties</td>\n",
       "      <td>JavaMLWritable</td>\n",
       "      <td>TypeConverters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HasEmbeddingsProperties</td>\n",
       "      <td>JavaModel</td>\n",
       "      <td>keyword_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0                     1  \\\n",
       "0           AnnotatorApproach  HasExcludableStorage   \n",
       "1              AnnotatorModel            HasStorage   \n",
       "2         AnnotatorProperties       HasStorageModel   \n",
       "3              CoverageResult         HasStorageRef   \n",
       "4            ExternalResource         JavaEstimator   \n",
       "5  HasCaseSensitiveProperties        JavaMLWritable   \n",
       "6     HasEmbeddingsProperties             JavaModel   \n",
       "\n",
       "                            2  \n",
       "0                       Param  \n",
       "1                      Params  \n",
       "2                      ReadAs  \n",
       "3  RecursiveAnnotatorApproach  \n",
       "4                   RegexRule  \n",
       "5              TypeConverters  \n",
       "6                keyword_only  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_methods(sparknlp.common,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:02:05.512838Z",
     "start_time": "2020-09-09T01:02:05.474461Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AlbertEmbeddings</td>\n",
       "      <td>NGramGenerator</td>\n",
       "      <td>Tokenizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AnnotatorApproach</td>\n",
       "      <td>NerApproach</td>\n",
       "      <td>TokenizerModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AnnotatorModel</td>\n",
       "      <td>NerConverter</td>\n",
       "      <td>TypeConverters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AnnotatorProperties</td>\n",
       "      <td>NerCrfApproach</td>\n",
       "      <td>TypedDependencyParserApproach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BertEmbeddings</td>\n",
       "      <td>NerCrfModel</td>\n",
       "      <td>TypedDependencyParserModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BertSentenceEmbeddings</td>\n",
       "      <td>NerDLApproach</td>\n",
       "      <td>UniversalSentenceEncoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BigTextMatcher</td>\n",
       "      <td>NerDLModel</td>\n",
       "      <td>ViveknSentimentApproach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BigTextMatcherModel</td>\n",
       "      <td>NerOverwriter</td>\n",
       "      <td>ViveknSentimentModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ChunkEmbeddings</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>WordEmbeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ChunkTokenizer</td>\n",
       "      <td>NormalizerModel</td>\n",
       "      <td>WordEmbeddingsModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ChunkTokenizerModel</td>\n",
       "      <td>NorvigSweetingApproach</td>\n",
       "      <td>XlnetEmbeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunker</td>\n",
       "      <td>NorvigSweetingModel</td>\n",
       "      <td>YakeModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ClassifierDLApproach</td>\n",
       "      <td>Param</td>\n",
       "      <td>annotators</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ClassifierDLModel</td>\n",
       "      <td>Params</td>\n",
       "      <td>classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ContextSpellCheckerApproach</td>\n",
       "      <td>PerceptronApproach</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ContextSpellCheckerModel</td>\n",
       "      <td>PerceptronModel</td>\n",
       "      <td>context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CoverageResult</td>\n",
       "      <td>ReadAs</td>\n",
       "      <td>crf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DateMatcher</td>\n",
       "      <td>RecursiveAnnotatorApproach</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DateMatcherUtils</td>\n",
       "      <td>RecursiveTokenizer</td>\n",
       "      <td>dep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DeepSentenceDetector</td>\n",
       "      <td>RecursiveTokenizerModel</td>\n",
       "      <td>dl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DependencyParserApproach</td>\n",
       "      <td>RegexMatcher</td>\n",
       "      <td>embeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DependencyParserModel</td>\n",
       "      <td>RegexMatcherModel</td>\n",
       "      <td>keyword</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ElmoEmbeddings</td>\n",
       "      <td>RegexRule</td>\n",
       "      <td>keyword_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ExternalResource</td>\n",
       "      <td>RegexTokenizer</td>\n",
       "      <td>ld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HasCaseSensitiveProperties</td>\n",
       "      <td>SentenceDetector</td>\n",
       "      <td>ner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>HasEmbeddingsProperties</td>\n",
       "      <td>SentenceDetectorParams</td>\n",
       "      <td>norvig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HasExcludableStorage</td>\n",
       "      <td>SentenceEmbeddings</td>\n",
       "      <td>parser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>HasStorage</td>\n",
       "      <td>SentimentDLApproach</td>\n",
       "      <td>perceptron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>HasStorageModel</td>\n",
       "      <td>SentimentDLModel</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>HasStorageRef</td>\n",
       "      <td>SentimentDetector</td>\n",
       "      <td>pragmatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>JavaEstimator</td>\n",
       "      <td>SentimentDetectorModel</td>\n",
       "      <td>regex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>JavaMLWritable</td>\n",
       "      <td>Stemmer</td>\n",
       "      <td>sbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>JavaModel</td>\n",
       "      <td>StopWordsCleaner</td>\n",
       "      <td>sda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LanguageDetectorDL</td>\n",
       "      <td>SymmetricDeleteApproach</td>\n",
       "      <td>spell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lemmatizer</td>\n",
       "      <td>SymmetricDeleteModel</td>\n",
       "      <td>symmetric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LemmatizerModel</td>\n",
       "      <td>TextMatcher</td>\n",
       "      <td>typdep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>MultiClassifierDLApproach</td>\n",
       "      <td>TextMatcherModel</td>\n",
       "      <td>vivekn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>MultiClassifierDLModel</td>\n",
       "      <td>Token2Chunk</td>\n",
       "      <td>yake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>MultiDateMatcher</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0                           1  \\\n",
       "0              AlbertEmbeddings              NGramGenerator   \n",
       "1             AnnotatorApproach                 NerApproach   \n",
       "2                AnnotatorModel                NerConverter   \n",
       "3           AnnotatorProperties              NerCrfApproach   \n",
       "4                BertEmbeddings                 NerCrfModel   \n",
       "5        BertSentenceEmbeddings               NerDLApproach   \n",
       "6                BigTextMatcher                  NerDLModel   \n",
       "7           BigTextMatcherModel               NerOverwriter   \n",
       "8               ChunkEmbeddings                  Normalizer   \n",
       "9                ChunkTokenizer             NormalizerModel   \n",
       "10          ChunkTokenizerModel      NorvigSweetingApproach   \n",
       "11                      Chunker         NorvigSweetingModel   \n",
       "12         ClassifierDLApproach                       Param   \n",
       "13            ClassifierDLModel                      Params   \n",
       "14  ContextSpellCheckerApproach          PerceptronApproach   \n",
       "15     ContextSpellCheckerModel             PerceptronModel   \n",
       "16               CoverageResult                      ReadAs   \n",
       "17                  DateMatcher  RecursiveAnnotatorApproach   \n",
       "18             DateMatcherUtils          RecursiveTokenizer   \n",
       "19         DeepSentenceDetector     RecursiveTokenizerModel   \n",
       "20     DependencyParserApproach                RegexMatcher   \n",
       "21        DependencyParserModel           RegexMatcherModel   \n",
       "22               ElmoEmbeddings                   RegexRule   \n",
       "23             ExternalResource              RegexTokenizer   \n",
       "24   HasCaseSensitiveProperties            SentenceDetector   \n",
       "25      HasEmbeddingsProperties      SentenceDetectorParams   \n",
       "26         HasExcludableStorage          SentenceEmbeddings   \n",
       "27                   HasStorage         SentimentDLApproach   \n",
       "28              HasStorageModel            SentimentDLModel   \n",
       "29                HasStorageRef           SentimentDetector   \n",
       "30                JavaEstimator      SentimentDetectorModel   \n",
       "31               JavaMLWritable                     Stemmer   \n",
       "32                    JavaModel            StopWordsCleaner   \n",
       "33           LanguageDetectorDL     SymmetricDeleteApproach   \n",
       "34                   Lemmatizer        SymmetricDeleteModel   \n",
       "35              LemmatizerModel                 TextMatcher   \n",
       "36    MultiClassifierDLApproach            TextMatcherModel   \n",
       "37       MultiClassifierDLModel                 Token2Chunk   \n",
       "38             MultiDateMatcher                               \n",
       "\n",
       "                                2  \n",
       "0                       Tokenizer  \n",
       "1                  TokenizerModel  \n",
       "2                  TypeConverters  \n",
       "3   TypedDependencyParserApproach  \n",
       "4      TypedDependencyParserModel  \n",
       "5        UniversalSentenceEncoder  \n",
       "6         ViveknSentimentApproach  \n",
       "7            ViveknSentimentModel  \n",
       "8                  WordEmbeddings  \n",
       "9             WordEmbeddingsModel  \n",
       "10                XlnetEmbeddings  \n",
       "11                      YakeModel  \n",
       "12                     annotators  \n",
       "13                     classifier  \n",
       "14                            com  \n",
       "15                        context  \n",
       "16                            crf  \n",
       "17                           deep  \n",
       "18                            dep  \n",
       "19                             dl  \n",
       "20                     embeddings  \n",
       "21                        keyword  \n",
       "22                   keyword_only  \n",
       "23                             ld  \n",
       "24                            ner  \n",
       "25                         norvig  \n",
       "26                         parser  \n",
       "27                     perceptron  \n",
       "28                            pos  \n",
       "29                      pragmatic  \n",
       "30                          regex  \n",
       "31                            sbd  \n",
       "32                            sda  \n",
       "33                          spell  \n",
       "34                      symmetric  \n",
       "35                         typdep  \n",
       "36                         vivekn  \n",
       "37                           yake  \n",
       "38                                 "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_methods(sparknlp.embeddings,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bert using sparknlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:14:36.496491Z",
     "start_time": "2020-09-09T00:14:33.368846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert_base_cased download started this may take some time.\n",
      "Approximate size to download 389.1 MB\n",
      "[OK!]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[text: string, label: bigint, document: array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>, token: array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>, embeddings: array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "document_assembler = sparknlp.DocumentAssembler()\\\n",
    "  .setInputCol(\"text\")\\\n",
    "  .setOutputCol(\"document\")\n",
    "\n",
    "tokenizer = sparknlp.embeddings.Tokenizer().setInputCols([\"document\"])\\\n",
    "  .setOutputCol(\"token\")\n",
    " \n",
    "word_embeddings = sparknlp.embeddings.BertEmbeddings.pretrained('bert_base_cased', 'en')\\\n",
    "  .setInputCols([\"document\", \"token\"])\\\n",
    "  .setOutputCol(\"embeddings\")\n",
    "\n",
    "\n",
    "bert_pipeline = sparknlp.base.Pipeline().setStages(\n",
    "  [\n",
    "    document_assembler,\n",
    "    tokenizer,\n",
    "    word_embeddings\n",
    "  ]\n",
    ")\n",
    "\n",
    "sdf_bert = bert_pipeline.fit(sdf).transform(sdf)\n",
    "display(sdf_bert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:15:00.367843Z",
     "start_time": "2020-09-09T00:14:58.509278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|                text|label|            document|               token|          embeddings|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "|New York is the g...|    0|[[document, 0, 41...|[[token, 0, 2, Ne...|[[word_embeddings...|\n",
      "|The beauty of Par...|    1|[[document, 0, 26...|[[token, 0, 2, Th...|[[word_embeddings...|\n",
      "|The Centre Pompid...|    1|[[document, 0, 30...|[[token, 0, 2, Th...|[[word_embeddings...|\n",
      "+--------------------+-----+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf_bert.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling: logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:19:25.403266Z",
     "start_time": "2020-09-09T00:19:25.288377Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[text: string, label: bigint, document: array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>, token: array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>, embeddings: array<struct<annotatorType:string,begin:int,end:int,result:string,metadata:map<string,string>,embeddings:array<float>>>, doc_vector: array<double>]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pyspark.sql.functions as F\n",
    "import pyspark.sql.types as T\n",
    "\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT\n",
    "\n",
    "def avg_vectors(bert_vectors):\n",
    "    length = len(bert_vectors[0][\"embeddings\"])\n",
    "    avg_vec = [0] * length\n",
    "    for vec in bert_vectors:\n",
    "        for i, x in enumerate(vec[\"embeddings\"]):\n",
    "            avg_vec[i] += x\n",
    "        avg_vec[i] = avg_vec[i] / length\n",
    "    return avg_vec\n",
    "\n",
    "\n",
    "#create a udf\n",
    "avg_vectors_udf = F.udf(avg_vectors, T.ArrayType(T.DoubleType()))\n",
    "df_doc_vec = df_bert.withColumn(\"doc_vector\", avg_vectors_udf(F.col(\"embeddings\")))\n",
    "display(df_doc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:24:53.698886Z",
     "start_time": "2020-09-09T00:24:52.275367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: 0.6936644983903933\n"
     ]
    }
   ],
   "source": [
    "def dense_vector(vec):\n",
    "    return Vectors.dense(vec)\n",
    "\n",
    "dense_vector_udf = F.udf(dense_vector, VectorUDT())\n",
    "training = df_doc_vec.withColumn(\"features\", dense_vector_udf(F.col(\"doc_vector\")))\n",
    "\n",
    "\n",
    "model = LogisticRegression(labelCol=\"label\", featuresCol=\"features\",\n",
    "                        maxIter=10, regParam=0.3, elasticNetParam=0.8)\n",
    "model = model.fit(training)\n",
    "# print(\"Coefficients: \" + str(model.coefficients))\n",
    "print(\"Intercept: \" + str(model.intercept))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python36(myspark)",
   "language": "python",
   "name": "mysparknlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
