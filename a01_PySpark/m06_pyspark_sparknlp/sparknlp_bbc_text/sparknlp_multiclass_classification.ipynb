{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Description\" data-toc-modified-id=\"Description-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Description</a></span></li><li><span><a href=\"#Sparknlp-setup\" data-toc-modified-id=\"Sparknlp-setup-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Sparknlp setup</a></span></li><li><span><a href=\"#Useful-Functions\" data-toc-modified-id=\"Useful-Functions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Useful Functions</a></span></li><li><span><a href=\"#Load-the-libraries\" data-toc-modified-id=\"Load-the-libraries-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Load the libraries</a></span></li><li><span><a href=\"#sparknlp-API\" data-toc-modified-id=\"sparknlp-API-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>sparknlp API</a></span></li><li><span><a href=\"#Train-test-split\" data-toc-modified-id=\"Train-test-split-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Train test split</a></span></li><li><span><a href=\"#NLP-Pipeline\" data-toc-modified-id=\"NLP-Pipeline-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>NLP Pipeline</a></span><ul class=\"toc-item\"><li><span><a href=\"#Document-assembling\" data-toc-modified-id=\"Document-assembling-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Document assembling</a></span></li><li><span><a href=\"#Tokenizing\" data-toc-modified-id=\"Tokenizing-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Tokenizing</a></span></li><li><span><a href=\"#Normalizer\" data-toc-modified-id=\"Normalizer-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Normalizer</a></span></li><li><span><a href=\"#Remove-stopwords\" data-toc-modified-id=\"Remove-stopwords-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Remove stopwords</a></span></li><li><span><a href=\"#Stemming\" data-toc-modified-id=\"Stemming-7.5\"><span class=\"toc-item-num\">7.5&nbsp;&nbsp;</span>Stemming</a></span></li><li><span><a href=\"#Finisher\" data-toc-modified-id=\"Finisher-7.6\"><span class=\"toc-item-num\">7.6&nbsp;&nbsp;</span>Finisher</a></span></li><li><span><a href=\"#TF-IDF\" data-toc-modified-id=\"TF-IDF-7.7\"><span class=\"toc-item-num\">7.7&nbsp;&nbsp;</span>TF-IDF</a></span></li><li><span><a href=\"#String-Indexing\" data-toc-modified-id=\"String-Indexing-7.8\"><span class=\"toc-item-num\">7.8&nbsp;&nbsp;</span>String Indexing</a></span></li><li><span><a href=\"#Classifier-Model\" data-toc-modified-id=\"Classifier-Model-7.9\"><span class=\"toc-item-num\">7.9&nbsp;&nbsp;</span>Classifier Model</a></span></li><li><span><a href=\"#Create-pipeline\" data-toc-modified-id=\"Create-pipeline-7.10\"><span class=\"toc-item-num\">7.10&nbsp;&nbsp;</span>Create pipeline</a></span></li></ul></li><li><span><a href=\"#Train-the-model\" data-toc-modified-id=\"Train-the-model-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Train the model</a></span></li><li><span><a href=\"#Model-Predictions\" data-toc-modified-id=\"Model-Predictions-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Model Predictions</a></span></li><li><span><a href=\"#Model-evaluation\" data-toc-modified-id=\"Model-evaluation-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Model evaluation</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "BBC data link: https://www.kaggle.com/yufengdev/bbc-text-categorization?#Get-the-data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparknlp setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:47:14.980025Z",
     "start_time": "2020-09-09T00:47:14.973658Z"
    }
   },
   "outputs": [],
   "source": [
    "#=============== setup sparknlp\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/Users/poudel/opt/miniconda3/envs/mysparknlp/lib/python3.7/site-packages\")\n",
    "os.environ[\"SPARK_HOME\"] = \"/Users/poudel/Softwares/Spark/spark-2.4.4-bin-hadoop2.7\"\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"/Users/poudel/opt/miniconda3/envs/mysparknlp/bin/python\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"jupyter\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON_OPTS\"] = \"notebook\"\n",
    "#================ setup sparknlp end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Useful Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:57:37.860677Z",
     "start_time": "2020-09-09T00:57:37.825511Z"
    }
   },
   "outputs": [],
   "source": [
    "def show_methods(obj, ncols=7,\n",
    "            start=None, inside=None,exclude=None,\n",
    "            caps_only=False,lower_only=False,\n",
    "                            printt=False):\n",
    "    \"\"\" Show all the attributes of a given method.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    obj: object\n",
    "        Name of python object. eg. list, pd.DataFrame\n",
    "    ncols: int\n",
    "        Number of columns\n",
    "    start: str\n",
    "        Substring the attribute starsts with.\n",
    "    inside: str or tuple or list\n",
    "        Show only these attributes if given substring exists.\n",
    "    exclude: str or tuple or list\n",
    "        Exclude these exact elements\n",
    "    caps_only: bool\n",
    "        Show only Title case words\n",
    "    lower_only: bool\n",
    "        Show only lowercase case words\n",
    "    printt: bool\n",
    "        Print the dataframe or not.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # print(f'Object Type: {type(obj)}\\n')\n",
    "    lst = [i for i in dir(obj) if i[0]!='_' ]\n",
    "\n",
    "    # exclude usual imports\n",
    "    usual_imports = ['np','pd','os','sys','time','psycopg2',\n",
    "                    'plt','string','px',\n",
    "                    're','nltk','sklearn','spacy']\n",
    "    lst = [i for i in lst\n",
    "            if i not in usual_imports ]\n",
    "\n",
    "    # capital only (for classes)\n",
    "    if caps_only:\n",
    "        lst = [i for i in lst if i[0].isupper()]\n",
    "\n",
    "    # lowercase only (method attributes)\n",
    "    if lower_only:\n",
    "        lst = [i for i in lst if i[0].islower()]\n",
    "\n",
    "    # starts with something\n",
    "    if isinstance(start,str):\n",
    "        lst = [i for i in lst if i.startswith(start)]\n",
    "\n",
    "    if isinstance(start,tuple) or isinstance(start,list):\n",
    "        lst = [i for i in lst for start_i in start\n",
    "                if i.startswith(start_i)]\n",
    "\n",
    "    # inside something\n",
    "    if isinstance(inside,str):\n",
    "        lst = [i for i in lst if inside in i]\n",
    "    if isinstance(inside,tuple) or isinstance(inside,list):\n",
    "        lst = [i for i in lst for inside_i in inside\n",
    "                if inside_i in i]\n",
    "\n",
    "    # exclude substring\n",
    "    if isinstance(exclude,str):\n",
    "        lst = [i for i in lst if i != exclude]\n",
    "\n",
    "    if isinstance(exclude,tuple) or isinstance(exclude,list):\n",
    "        lst = [i for i in lst if i not in exclude]\n",
    "\n",
    "    # ouput dataframe\n",
    "    df = pd.DataFrame(np.array_split(lst,ncols)).T.fillna('')\n",
    "\n",
    "    # for terminal sometimes we need to print\n",
    "    if printt:\n",
    "        print(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:47:16.187743Z",
     "start_time": "2020-09-09T00:47:14.982506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('numpy', '1.19.1'), ('pandas', '0.23.4'), ('seaborn', '0.10.1')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('max_columns',100)\n",
    "\n",
    "import time,os,json\n",
    "time_start_notebook = time.time()\n",
    "home = os.path.expanduser('~')\n",
    "SEED=100\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "[(x.__name__,x.__version__) for x in [np,pd,sns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:05:40.641296Z",
     "start_time": "2020-09-09T01:05:40.627145Z"
    }
   },
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:25:22.316960Z",
     "start_time": "2020-09-09T01:25:22.313603Z"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:47:26.913926Z",
     "start_time": "2020-09-09T00:47:21.025025Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_location = r'bbc-text.csv'\n",
    "file_type = \"csv\"\n",
    "infer_schema = \"true\"\n",
    "first_row_is_header = \"true\"\n",
    "delimiter = \",\"\n",
    "\n",
    "sdf = (spark.read.format(file_type)\n",
    "  .option(\"inferSchema\", infer_schema)\n",
    "  .option(\"header\", first_row_is_header)\n",
    "  .option(\"sep\", delimiter)\n",
    "  .load(file_location)\n",
    "     )\n",
    "\n",
    "sdf.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:47:27.059099Z",
     "start_time": "2020-09-09T00:47:26.916075Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+\n",
      "|category|                text|\n",
      "+--------+--------------------+\n",
      "|    tech|tv future in the ...|\n",
      "|business|worldcom boss  le...|\n",
      "+--------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:20:59.125238Z",
     "start_time": "2020-09-09T01:20:58.287784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----+\n",
      "|     category|count|\n",
      "+-------------+-----+\n",
      "|        sport|  511|\n",
      "|     politics|  417|\n",
      "|entertainment|  386|\n",
      "|     business|  510|\n",
      "|         tech|  401|\n",
      "+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.groupby('category').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:26:04.330490Z",
     "start_time": "2020-09-09T01:26:03.512757Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|count(DISTINCT category)|\n",
      "+------------------------+\n",
      "|                       5|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf.agg(F.countDistinct(\"category\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sparknlp API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:59:01.110794Z",
     "start_time": "2020-09-09T00:59:01.091278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chunk2Doc</td>\n",
       "      <td>Finisher</td>\n",
       "      <td>TokenAssembler</td>\n",
       "      <td>annotator</td>\n",
       "      <td>base</td>\n",
       "      <td>embeddings</td>\n",
       "      <td>start</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doc2Chunk</td>\n",
       "      <td>SparkSession</td>\n",
       "      <td>annotation</td>\n",
       "      <td>annotators</td>\n",
       "      <td>common</td>\n",
       "      <td>internal</td>\n",
       "      <td>version</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DocumentAssembler</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0             1               2           3       4  \\\n",
       "0          Chunk2Doc      Finisher  TokenAssembler   annotator    base   \n",
       "1          Doc2Chunk  SparkSession      annotation  annotators  common   \n",
       "2  DocumentAssembler                                                     \n",
       "\n",
       "            5        6  \n",
       "0  embeddings    start  \n",
       "1    internal  version  \n",
       "2                       "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_methods(sparknlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:59:17.108165Z",
     "start_time": "2020-09-09T00:59:17.096543Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABC</td>\n",
       "      <td>Finisher</td>\n",
       "      <td>RecursiveEstimator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Annotation</td>\n",
       "      <td>HasRecursiveFit</td>\n",
       "      <td>RecursivePipeline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AnnotatorProperties</td>\n",
       "      <td>HasRecursiveTransform</td>\n",
       "      <td>RecursivePipelineModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AnnotatorTransformer</td>\n",
       "      <td>JavaEstimator</td>\n",
       "      <td>RecursiveTransformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chunk2Doc</td>\n",
       "      <td>LightPipeline</td>\n",
       "      <td>TokenAssembler</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Doc2Chunk</td>\n",
       "      <td>Param</td>\n",
       "      <td>Transformer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DocumentAssembler</td>\n",
       "      <td>Params</td>\n",
       "      <td>TypeConverters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EmbeddingsFinisher</td>\n",
       "      <td>Pipeline</td>\n",
       "      <td>keyword_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Estimator</td>\n",
       "      <td>PipelineModel</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0                      1                       2\n",
       "0                   ABC               Finisher      RecursiveEstimator\n",
       "1            Annotation        HasRecursiveFit       RecursivePipeline\n",
       "2   AnnotatorProperties  HasRecursiveTransform  RecursivePipelineModel\n",
       "3  AnnotatorTransformer          JavaEstimator    RecursiveTransformer\n",
       "4             Chunk2Doc          LightPipeline          TokenAssembler\n",
       "5             Doc2Chunk                  Param             Transformer\n",
       "6     DocumentAssembler                 Params          TypeConverters\n",
       "7    EmbeddingsFinisher               Pipeline            keyword_only\n",
       "8             Estimator          PipelineModel                        "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_methods(sparknlp.base,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:59:36.720232Z",
     "start_time": "2020-09-09T00:59:36.706795Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AnnotatorApproach</td>\n",
       "      <td>HasExcludableStorage</td>\n",
       "      <td>Param</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AnnotatorModel</td>\n",
       "      <td>HasStorage</td>\n",
       "      <td>Params</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AnnotatorProperties</td>\n",
       "      <td>HasStorageModel</td>\n",
       "      <td>ReadAs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CoverageResult</td>\n",
       "      <td>HasStorageRef</td>\n",
       "      <td>RecursiveAnnotatorApproach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ExternalResource</td>\n",
       "      <td>JavaEstimator</td>\n",
       "      <td>RegexRule</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HasCaseSensitiveProperties</td>\n",
       "      <td>JavaMLWritable</td>\n",
       "      <td>TypeConverters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HasEmbeddingsProperties</td>\n",
       "      <td>JavaModel</td>\n",
       "      <td>keyword_only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0                     1  \\\n",
       "0           AnnotatorApproach  HasExcludableStorage   \n",
       "1              AnnotatorModel            HasStorage   \n",
       "2         AnnotatorProperties       HasStorageModel   \n",
       "3              CoverageResult         HasStorageRef   \n",
       "4            ExternalResource         JavaEstimator   \n",
       "5  HasCaseSensitiveProperties        JavaMLWritable   \n",
       "6     HasEmbeddingsProperties             JavaModel   \n",
       "\n",
       "                            2  \n",
       "0                       Param  \n",
       "1                      Params  \n",
       "2                      ReadAs  \n",
       "3  RecursiveAnnotatorApproach  \n",
       "4                   RegexRule  \n",
       "5              TypeConverters  \n",
       "6                keyword_only  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_methods(sparknlp.common,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:59:48.796387Z",
     "start_time": "2020-09-09T00:59:48.779217Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AlbertEmbeddings</td>\n",
       "      <td>NGramGenerator</td>\n",
       "      <td>Tokenizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AnnotatorApproach</td>\n",
       "      <td>NerApproach</td>\n",
       "      <td>TokenizerModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AnnotatorModel</td>\n",
       "      <td>NerConverter</td>\n",
       "      <td>TypeConverters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AnnotatorProperties</td>\n",
       "      <td>NerCrfApproach</td>\n",
       "      <td>TypedDependencyParserApproach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BertEmbeddings</td>\n",
       "      <td>NerCrfModel</td>\n",
       "      <td>TypedDependencyParserModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BertSentenceEmbeddings</td>\n",
       "      <td>NerDLApproach</td>\n",
       "      <td>UniversalSentenceEncoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BigTextMatcher</td>\n",
       "      <td>NerDLModel</td>\n",
       "      <td>ViveknSentimentApproach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BigTextMatcherModel</td>\n",
       "      <td>NerOverwriter</td>\n",
       "      <td>ViveknSentimentModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ChunkEmbeddings</td>\n",
       "      <td>Normalizer</td>\n",
       "      <td>WordEmbeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ChunkTokenizer</td>\n",
       "      <td>NormalizerModel</td>\n",
       "      <td>WordEmbeddingsModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ChunkTokenizerModel</td>\n",
       "      <td>NorvigSweetingApproach</td>\n",
       "      <td>XlnetEmbeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Chunker</td>\n",
       "      <td>NorvigSweetingModel</td>\n",
       "      <td>YakeModel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>ClassifierDLApproach</td>\n",
       "      <td>Param</td>\n",
       "      <td>annotators</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ClassifierDLModel</td>\n",
       "      <td>Params</td>\n",
       "      <td>classifier</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ContextSpellCheckerApproach</td>\n",
       "      <td>PerceptronApproach</td>\n",
       "      <td>com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ContextSpellCheckerModel</td>\n",
       "      <td>PerceptronModel</td>\n",
       "      <td>context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CoverageResult</td>\n",
       "      <td>ReadAs</td>\n",
       "      <td>crf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DateMatcher</td>\n",
       "      <td>RecursiveAnnotatorApproach</td>\n",
       "      <td>deep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>DateMatcherUtils</td>\n",
       "      <td>RecursiveTokenizer</td>\n",
       "      <td>dep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>DeepSentenceDetector</td>\n",
       "      <td>RecursiveTokenizerModel</td>\n",
       "      <td>dl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DependencyParserApproach</td>\n",
       "      <td>RegexMatcher</td>\n",
       "      <td>embeddings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>DependencyParserModel</td>\n",
       "      <td>RegexMatcherModel</td>\n",
       "      <td>keyword</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ElmoEmbeddings</td>\n",
       "      <td>RegexRule</td>\n",
       "      <td>keyword_only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ExternalResource</td>\n",
       "      <td>RegexTokenizer</td>\n",
       "      <td>ld</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>HasCaseSensitiveProperties</td>\n",
       "      <td>SentenceDetector</td>\n",
       "      <td>ner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>HasEmbeddingsProperties</td>\n",
       "      <td>SentenceDetectorParams</td>\n",
       "      <td>norvig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>HasExcludableStorage</td>\n",
       "      <td>SentenceEmbeddings</td>\n",
       "      <td>parser</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>HasStorage</td>\n",
       "      <td>SentimentDLApproach</td>\n",
       "      <td>perceptron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>HasStorageModel</td>\n",
       "      <td>SentimentDLModel</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>HasStorageRef</td>\n",
       "      <td>SentimentDetector</td>\n",
       "      <td>pragmatic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>JavaEstimator</td>\n",
       "      <td>SentimentDetectorModel</td>\n",
       "      <td>regex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>JavaMLWritable</td>\n",
       "      <td>Stemmer</td>\n",
       "      <td>sbd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>JavaModel</td>\n",
       "      <td>StopWordsCleaner</td>\n",
       "      <td>sda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LanguageDetectorDL</td>\n",
       "      <td>SymmetricDeleteApproach</td>\n",
       "      <td>spell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lemmatizer</td>\n",
       "      <td>SymmetricDeleteModel</td>\n",
       "      <td>symmetric</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>LemmatizerModel</td>\n",
       "      <td>TextMatcher</td>\n",
       "      <td>typdep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>MultiClassifierDLApproach</td>\n",
       "      <td>TextMatcherModel</td>\n",
       "      <td>vivekn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>MultiClassifierDLModel</td>\n",
       "      <td>Token2Chunk</td>\n",
       "      <td>yake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>MultiDateMatcher</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              0                           1  \\\n",
       "0              AlbertEmbeddings              NGramGenerator   \n",
       "1             AnnotatorApproach                 NerApproach   \n",
       "2                AnnotatorModel                NerConverter   \n",
       "3           AnnotatorProperties              NerCrfApproach   \n",
       "4                BertEmbeddings                 NerCrfModel   \n",
       "5        BertSentenceEmbeddings               NerDLApproach   \n",
       "6                BigTextMatcher                  NerDLModel   \n",
       "7           BigTextMatcherModel               NerOverwriter   \n",
       "8               ChunkEmbeddings                  Normalizer   \n",
       "9                ChunkTokenizer             NormalizerModel   \n",
       "10          ChunkTokenizerModel      NorvigSweetingApproach   \n",
       "11                      Chunker         NorvigSweetingModel   \n",
       "12         ClassifierDLApproach                       Param   \n",
       "13            ClassifierDLModel                      Params   \n",
       "14  ContextSpellCheckerApproach          PerceptronApproach   \n",
       "15     ContextSpellCheckerModel             PerceptronModel   \n",
       "16               CoverageResult                      ReadAs   \n",
       "17                  DateMatcher  RecursiveAnnotatorApproach   \n",
       "18             DateMatcherUtils          RecursiveTokenizer   \n",
       "19         DeepSentenceDetector     RecursiveTokenizerModel   \n",
       "20     DependencyParserApproach                RegexMatcher   \n",
       "21        DependencyParserModel           RegexMatcherModel   \n",
       "22               ElmoEmbeddings                   RegexRule   \n",
       "23             ExternalResource              RegexTokenizer   \n",
       "24   HasCaseSensitiveProperties            SentenceDetector   \n",
       "25      HasEmbeddingsProperties      SentenceDetectorParams   \n",
       "26         HasExcludableStorage          SentenceEmbeddings   \n",
       "27                   HasStorage         SentimentDLApproach   \n",
       "28              HasStorageModel            SentimentDLModel   \n",
       "29                HasStorageRef           SentimentDetector   \n",
       "30                JavaEstimator      SentimentDetectorModel   \n",
       "31               JavaMLWritable                     Stemmer   \n",
       "32                    JavaModel            StopWordsCleaner   \n",
       "33           LanguageDetectorDL     SymmetricDeleteApproach   \n",
       "34                   Lemmatizer        SymmetricDeleteModel   \n",
       "35              LemmatizerModel                 TextMatcher   \n",
       "36    MultiClassifierDLApproach            TextMatcherModel   \n",
       "37       MultiClassifierDLModel                 Token2Chunk   \n",
       "38             MultiDateMatcher                               \n",
       "\n",
       "                                2  \n",
       "0                       Tokenizer  \n",
       "1                  TokenizerModel  \n",
       "2                  TypeConverters  \n",
       "3   TypedDependencyParserApproach  \n",
       "4      TypedDependencyParserModel  \n",
       "5        UniversalSentenceEncoder  \n",
       "6         ViveknSentimentApproach  \n",
       "7            ViveknSentimentModel  \n",
       "8                  WordEmbeddings  \n",
       "9             WordEmbeddingsModel  \n",
       "10                XlnetEmbeddings  \n",
       "11                      YakeModel  \n",
       "12                     annotators  \n",
       "13                     classifier  \n",
       "14                            com  \n",
       "15                        context  \n",
       "16                            crf  \n",
       "17                           deep  \n",
       "18                            dep  \n",
       "19                             dl  \n",
       "20                     embeddings  \n",
       "21                        keyword  \n",
       "22                   keyword_only  \n",
       "23                             ld  \n",
       "24                            ner  \n",
       "25                         norvig  \n",
       "26                         parser  \n",
       "27                     perceptron  \n",
       "28                            pos  \n",
       "29                      pragmatic  \n",
       "30                          regex  \n",
       "31                            sbd  \n",
       "32                            sda  \n",
       "33                          spell  \n",
       "34                      symmetric  \n",
       "35                         typdep  \n",
       "36                         vivekn  \n",
       "37                           yake  \n",
       "38                                 "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_methods(sparknlp.embeddings,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:47:27.648584Z",
     "start_time": "2020-09-09T00:47:27.060971Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1561, 664)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdf_train, sdf_test = sdf.randomSplit([0.7, 0.3], seed=SEED)\n",
    "\n",
    "sdf_train.count(), sdf_test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:47:27.653736Z",
     "start_time": "2020-09-09T00:47:27.651088Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, StringIndexer, SQLTransformer,IndexToString\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document assembling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:47:27.700118Z",
     "start_time": "2020-09-09T00:47:27.658317Z"
    }
   },
   "outputs": [],
   "source": [
    "document_assembler = sparknlp.DocumentAssembler()\\\n",
    "  .setInputCol(\"text\")\\\n",
    "  .setOutputCol(\"document\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:48:00.492711Z",
     "start_time": "2020-09-09T00:48:00.489305Z"
    }
   },
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:48:06.945833Z",
     "start_time": "2020-09-09T00:48:06.922986Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = sparknlp.embeddings.Tokenizer() \\\n",
    "  .setInputCols([\"document\"]) \\\n",
    "  .setOutputCol(\"token\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:49:19.974398Z",
     "start_time": "2020-09-09T00:49:19.965057Z"
    }
   },
   "outputs": [],
   "source": [
    " normalizer = sparknlp.annotator.Normalizer() \\\n",
    "    .setInputCols([\"token\"]) \\\n",
    "    .setOutputCol(\"normalized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:51:11.776271Z",
     "start_time": "2020-09-09T00:51:11.670588Z"
    }
   },
   "outputs": [],
   "source": [
    "stopwords_cleaner = sparknlp.annotator.StopWordsCleaner()\\\n",
    "      .setInputCols(\"normalized\")\\\n",
    "      .setOutputCol(\"cleanTokens\")\\\n",
    "      .setCaseSensitive(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:51:31.106434Z",
     "start_time": "2020-09-09T00:51:31.097130Z"
    }
   },
   "outputs": [],
   "source": [
    "stemmer = sparknlp.annotator.Stemmer() \\\n",
    "    .setInputCols([\"cleanTokens\"]) \\\n",
    "    .setOutputCol(\"stem\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T00:53:12.941136Z",
     "start_time": "2020-09-09T00:53:12.931020Z"
    }
   },
   "outputs": [],
   "source": [
    "finisher = sparknlp.base.Finisher() \\\n",
    "    .setInputCols([\"stem\"]) \\\n",
    "    .setOutputCols([\"token_features\"]) \\\n",
    "    .setOutputAsArray(True) \\\n",
    "    .setCleanAnnotations(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "Ref: https://spark.apache.org/docs/2.1.0/ml-features.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:05:57.639426Z",
     "start_time": "2020-09-09T01:05:57.635466Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:10:40.171012Z",
     "start_time": "2020-09-09T01:10:40.130165Z"
    }
   },
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol=\"token_features\",\n",
    "                      outputCol=\"rawFeatures\",\n",
    "                      numFeatures=1000)\n",
    "\n",
    "idf = pyspark.ml.feature.IDF(inputCol=\"rawFeatures\",\n",
    "          outputCol=\"features\",\n",
    "          minDocFreq=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## String Indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:09:40.817051Z",
     "start_time": "2020-09-09T01:09:40.813622Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:08:21.965308Z",
     "start_time": "2020-09-09T01:08:21.949798Z"
    }
   },
   "outputs": [],
   "source": [
    "label_stringIdx = pyspark.ml.feature.StringIndexer(inputCol = \"category\", outputCol = \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:10:26.828960Z",
     "start_time": "2020-09-09T01:10:26.825647Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:11:31.379643Z",
     "start_time": "2020-09-09T01:11:31.370973Z"
    }
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(maxIter=10,\n",
    "                        regParam=0.3,\n",
    "                        elasticNetParam=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:11:56.405960Z",
     "start_time": "2020-09-09T01:11:56.395165Z"
    }
   },
   "outputs": [],
   "source": [
    "label_to_stringIdx = pyspark.ml.feature.IndexToString(inputCol=\"label\",\n",
    "                                   outputCol=\"article_class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:12:32.119521Z",
     "start_time": "2020-09-09T01:12:32.115984Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:12:34.317417Z",
     "start_time": "2020-09-09T01:12:34.313702Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp_pipeline = Pipeline(\n",
    "    stages=[document_assembler, \n",
    "            tokenizer,\n",
    "            normalizer,\n",
    "            stopwords_cleaner, \n",
    "            stemmer, \n",
    "            finisher,\n",
    "            hashingTF,\n",
    "            idf,\n",
    "            label_stringIdx,\n",
    "            lr,\n",
    "            label_to_stringIdx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:13:38.730682Z",
     "start_time": "2020-09-09T01:13:18.899079Z"
    }
   },
   "outputs": [],
   "source": [
    "pipeline_model = nlp_pipeline.fit(sdf_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:13:50.072766Z",
     "start_time": "2020-09-09T01:13:49.748155Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions =  pipeline_model.transform(sdf_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:15:10.262630Z",
     "start_time": "2020-09-09T01:15:03.722728Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy = 0.957831\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"accuracy\")\n",
    "\n",
    "\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(\"Accuracy = %g\" % (accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:16:54.525606Z",
     "start_time": "2020-09-09T01:16:45.178547Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weightedPrecision = 0.958096\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"weightedPrecision\")\n",
    "\n",
    "weightedPrecision = evaluator.evaluate(predictions)\n",
    "print(\"weightedPrecision = %g\" % (weightedPrecision))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-09T01:18:05.689474Z",
     "start_time": "2020-09-09T01:17:58.187583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weightedRecall = 0.957831\n"
     ]
    }
   ],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\",\n",
    "    predictionCol=\"prediction\",\n",
    "    metricName=\"weightedRecall\")\n",
    "\n",
    "weightedRecall = evaluator.evaluate(predictions)\n",
    "print(\"weightedRecall = %g\" % (weightedRecall))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python36(myspark)",
   "language": "python",
   "name": "mysparknlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
