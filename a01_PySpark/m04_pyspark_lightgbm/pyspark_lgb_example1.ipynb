{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Description\" data-toc-modified-id=\"Description-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Description</a></span></li><li><span><a href=\"#Load-the-libraries\" data-toc-modified-id=\"Load-the-libraries-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load the libraries</a></span></li><li><span><a href=\"#Load-the-data\" data-toc-modified-id=\"Load-the-data-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Load the data</a></span></li><li><span><a href=\"#Data-Preparation\" data-toc-modified-id=\"Data-Preparation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Data Preparation</a></span></li><li><span><a href=\"#Modelling\" data-toc-modified-id=\"Modelling-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Modelling</a></span><ul class=\"toc-item\"><li><span><a href=\"#Random-Forest\" data-toc-modified-id=\"Random-Forest-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Random Forest</a></span></li><li><span><a href=\"#Lightgbm\" data-toc-modified-id=\"Lightgbm-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Lightgbm</a></span></li><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Logistic Regression</a></span></li></ul></li><li><span><a href=\"#Different-models\" data-toc-modified-id=\"Different-models-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Different models</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "Github link: https://github.com/Azure/mmlspark  \n",
    "\n",
    "lightgbm doc: https://github.com/Azure/mmlspark/blob/master/docs/lightgbm.md  \n",
    "\n",
    "\n",
    "Regression:\n",
    "```python\n",
    "from mmlspark.lightgbm import LightGBMRegressor\n",
    "model = LightGBMRegressor(application='quantile',\n",
    "                          alpha=0.3,\n",
    "                          learningRate=0.3,\n",
    "                          numIterations=100,\n",
    "                          numLeaves=31).fit(train)\n",
    "```\n",
    "\n",
    "\n",
    "Classification:\n",
    "```python\n",
    "from mmlspark.lightgbm import LightGBMClassifier\n",
    "model = LightGBMClassifier(learningRate=0.3,\n",
    "                           numIterations=100,\n",
    "                           numLeaves=31).fit(train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T22:55:09.010731Z",
     "start_time": "2020-08-26T22:55:01.178665Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pyspark version: 2.4.6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "HOME = os.path.expanduser('~')\n",
    "\n",
    "import findspark\n",
    "# findspark.init(HOME + \"/Softwares/Spark/spark-3.0.0-bin-hadoop2.7\")\n",
    "\n",
    "# We need to use spark 2.4.6 to use lgbm\n",
    "findspark.init(HOME + \"/Softwares/Spark/spark-2.4.6-bin-hadoop2.7\")\n",
    "\n",
    "import pyspark\n",
    "from pyspark.sql.session import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "spark = (pyspark.sql.SparkSession.builder.appName(\"MyApp\")\n",
    "\n",
    "    # config for microsoft ml spark\n",
    "    .config(\"spark.jars.packages\", \"com.microsoft.ml.spark:mmlspark_2.11:1.0.0-rc2\") \n",
    "    .config(\"spark.jars.repositories\", \"https://mmlspark.azureedge.net/maven\")\n",
    "         \n",
    "    # usual\n",
    "    .getOrCreate()\n",
    "    )\n",
    "import mmlspark\n",
    "\n",
    "SEED = 100\n",
    "\n",
    "df_eval = pd.DataFrame({\n",
    "    \"Model\": [],\n",
    "    \"Description\": [],\n",
    "    \"Accuracy\": [],\n",
    "    \"Precision\": [],\n",
    "    \"AUC\": []\n",
    "})\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from mmlspark.lightgbm import LightGBMClassifier\n",
    "\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "print(f'pyspark version: {pyspark.__version__}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T22:55:16.816105Z",
     "start_time": "2020-08-26T22:55:09.013123Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6366, 6)\n",
      "root\n",
      " |-- rate_marriage: integer (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- yrs_married: double (nullable = true)\n",
      " |-- children: double (nullable = true)\n",
      " |-- religious: integer (nullable = true)\n",
      " |-- affairs: integer (nullable = true)\n",
      "\n",
      "None\n",
      "+-------------+----+-----------+--------+---------+-------+\n",
      "|rate_marriage| age|yrs_married|children|religious|affairs|\n",
      "+-------------+----+-----------+--------+---------+-------+\n",
      "|            5|32.0|        6.0|     1.0|        3|      0|\n",
      "|            4|22.0|        2.5|     0.0|        2|      0|\n",
      "|            3|32.0|        9.0|     3.0|        3|      1|\n",
      "|            3|27.0|       13.0|     3.0|        1|      1|\n",
      "|            4|22.0|        2.5|     0.0|        1|      1|\n",
      "+-------------+----+-----------+--------+---------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sdf = spark.read.csv('affairs.csv',inferSchema=True,header=True)\n",
    "print((sdf.count(),len(sdf.columns)))\n",
    "\n",
    "print(sdf.printSchema())\n",
    "sdf.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T22:55:16.827566Z",
     "start_time": "2020-08-26T22:55:16.819046Z"
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T22:55:17.031734Z",
     "start_time": "2020-08-26T22:55:16.829799Z"
    }
   },
   "outputs": [],
   "source": [
    "inputCols = ['rate_marriage', 'age', 'yrs_married', 'children', 'religious']\n",
    "assembler = VectorAssembler(inputCols=inputCols, outputCol=\"features\")\n",
    "\n",
    "sdf = assembler.transform(sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T22:55:17.075203Z",
     "start_time": "2020-08-26T22:55:17.033907Z"
    }
   },
   "outputs": [],
   "source": [
    "train,test = sdf.select(['features','affairs']).randomSplit([0.75,0.25],seed=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T22:55:17.605558Z",
     "start_time": "2020-08-26T22:55:17.076956Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4803"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T22:55:18.682471Z",
     "start_time": "2020-08-26T22:55:17.607601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|affairs|count|\n",
      "+-------+-----+\n",
      "|      1| 1561|\n",
      "|      0| 3242|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.groupBy('affairs').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T22:55:19.719978Z",
     "start_time": "2020-08-26T22:55:18.686673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|affairs|count|\n",
      "+-------+-----+\n",
      "|      1|  492|\n",
      "|      0| 1071|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test.groupBy('affairs').count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "```python\n",
    "RandomForestClassifier(\n",
    "    featuresCol='features',\n",
    "    labelCol='label',\n",
    "    predictionCol='prediction',\n",
    "    probabilityCol='probability',\n",
    "    rawPredictionCol='rawPrediction',\n",
    "    maxDepth=5,\n",
    "    maxBins=32,\n",
    "    minInstancesPerNode=1,\n",
    "    minInfoGain=0.0,\n",
    "    maxMemoryInMB=256,\n",
    "    cacheNodeIds=False,\n",
    "    checkpointInterval=10,\n",
    "    impurity='gini',\n",
    "    numTrees=20,\n",
    "    featureSubsetStrategy='auto',\n",
    "    seed=None,\n",
    "    subsamplingRate=1.0,\n",
    ")\n",
    "Docstring:     \n",
    "`Random Forest <http://en.wikipedia.org/wiki/Random_forest>`_\n",
    "learning algorithm for classification.\n",
    "It supports both binary and multiclass labels, as well as both continuous and categorical\n",
    "features.\n",
    "\n",
    ">>> import numpy\n",
    ">>> from numpy import allclose\n",
    ">>> from pyspark.ml.linalg import Vectors\n",
    ">>> from pyspark.ml.feature import StringIndexer\n",
    ">>> df = spark.createDataFrame([\n",
    "...     (1.0, Vectors.dense(1.0)),\n",
    "...     (0.0, Vectors.sparse(1, [], []))], [\"label\", \"features\"])\n",
    ">>> stringIndexer = StringIndexer(inputCol=\"label\", outputCol=\"indexed\")\n",
    ">>> si_model = stringIndexer.fit(df)\n",
    ">>> td = si_model.transform(df)\n",
    ">>> rf = RandomForestClassifier(numTrees=3, maxDepth=2, labelCol=\"indexed\", seed=42)\n",
    ">>> model = rf.fit(td)\n",
    ">>> model.featureImportances\n",
    "SparseVector(1, {0: 1.0})\n",
    ">>> allclose(model.treeWeights, [1.0, 1.0, 1.0])\n",
    "True\n",
    ">>> test0 = spark.createDataFrame([(Vectors.dense(-1.0),)], [\"features\"])\n",
    ">>> result = model.transform(test0).head()\n",
    ">>> result.prediction\n",
    "0.0\n",
    ">>> numpy.argmax(result.probability)\n",
    "0\n",
    ">>> numpy.argmax(result.rawPrediction)\n",
    "0\n",
    ">>> test1 = spark.createDataFrame([(Vectors.sparse(1, [0], [1.0]),)], [\"features\"])\n",
    ">>> model.transform(test1).head().prediction\n",
    "1.0\n",
    ">>> model.trees\n",
    "[DecisionTreeClassificationModel (uid=...) of depth..., DecisionTreeClassificationModel...]\n",
    ">>> rfc_path = temp_path + \"/rfc\"\n",
    ">>> rf.save(rfc_path)\n",
    ">>> rf2 = RandomForestClassifier.load(rfc_path)\n",
    ">>> rf2.getNumTrees()\n",
    "3\n",
    ">>> model_path = temp_path + \"/rfc_model\"\n",
    ">>> model.save(model_path)\n",
    ">>> model2 = RandomForestClassificationModel.load(model_path)\n",
    ">>> model.featureImportances == model2.featureImportances\n",
    "True\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T22:55:23.972361Z",
     "start_time": "2020-08-26T22:55:19.723886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>default</td>\n",
       "      <td>0.713372</td>\n",
       "      <td>0.691098</td>\n",
       "      <td>0.736099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Description  Accuracy  Precision       AUC\n",
       "0    rf     default  0.713372   0.691098  0.736099"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier(labelCol='affairs',seed=SEED)\n",
    "\n",
    "# model.save('lgb.pkl')\n",
    "# model = LightGBMClassifier.load('lgb.pkl')\n",
    "\n",
    "model = model.fit(train)\n",
    "test_preds = model.transform(test)\n",
    "\n",
    "acc = MulticlassClassificationEvaluator(\n",
    "    labelCol='affairs',\n",
    "    metricName='accuracy'\n",
    "    ).evaluate(test_preds)\n",
    "\n",
    "precision = MulticlassClassificationEvaluator(\n",
    "    labelCol='affairs',\n",
    "    metricName='weightedPrecision'\n",
    "    ).evaluate(test_preds)\n",
    "\n",
    "auc = BinaryClassificationEvaluator(\n",
    "    labelCol='affairs'\n",
    "   ).evaluate(test_preds)\n",
    "\n",
    "\n",
    "row = [\"rf\",'default',acc,precision,auc]\n",
    "\n",
    "df_eval.loc[len(df_eval)] = row\n",
    "df_eval = df_eval.drop_duplicates()\n",
    "df_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lightgbm\n",
    "\n",
    "```python\n",
    "LightGBMClassifier(\n",
    "    baggingFraction=1.0,\n",
    "    baggingFreq=0,\n",
    "    baggingSeed=3,\n",
    "    binSampleCount=200000,\n",
    "    boostFromAverage=True,\n",
    "    boostingType='gbdt',\n",
    "    categoricalSlotIndexes=[],\n",
    "    categoricalSlotNames=[],\n",
    "    defaultListenPort=12400,\n",
    "    driverListenPort=0,\n",
    "    earlyStoppingRound=0,\n",
    "    featureFraction=1.0,\n",
    "    featuresCol='features',\n",
    "    featuresShapCol='',\n",
    "    improvementTolerance=0.0,\n",
    "    initScoreCol=None,\n",
    "    isProvideTrainingMetric=False,\n",
    "    isUnbalance=False,\n",
    "    labelCol='label',\n",
    "    lambdaL1=0.0,\n",
    "    lambdaL2=0.0,\n",
    "    leafPredictionCol='',\n",
    "    learningRate=0.1,\n",
    "    maxBin=255,\n",
    "    maxBinByFeature=[],\n",
    "    maxDeltaStep=0.0,\n",
    "    maxDepth=-1,\n",
    "    metric='',\n",
    "    minDataInLeaf=20,\n",
    "    minGainToSplit=0.0,\n",
    "    minSumHessianInLeaf=0.001,\n",
    "    modelString='',\n",
    "    negBaggingFraction=1.0,\n",
    "    numBatches=0,\n",
    "    numIterations=100,\n",
    "    numLeaves=31,\n",
    "    numTasks=0,\n",
    "    objective='binary',\n",
    "    parallelism='data_parallel',\n",
    "    posBaggingFraction=1.0,\n",
    "    predictionCol='prediction',\n",
    "    probabilityCol='probability',\n",
    "    rawPredictionCol='rawPrediction',\n",
    "    repartitionByGroupingColumn=True,\n",
    "    slotNames=[],\n",
    "    thresholds=None,\n",
    "    timeout=1200.0,\n",
    "    topK=20,\n",
    "    useBarrierExecutionMode=False,\n",
    "    validationIndicatorCol=None,\n",
    "    verbosity=1,\n",
    "    weightCol=None,\n",
    ")\n",
    "Docstring:     \n",
    "Args:\n",
    "\n",
    "    baggingFraction (double): Bagging fraction (default: 1.0)\n",
    "    baggingFreq (int): Bagging frequency (default: 0)\n",
    "    baggingSeed (int): Bagging seed (default: 3)\n",
    "    binSampleCount (int): Number of samples considered at computing histogram bins (default: 200000)\n",
    "    boostFromAverage (bool): Adjusts initial score to the mean of labels for faster convergence (default: true)\n",
    "    boostingType (str): Default gbdt = traditional Gradient Boosting Decision Tree. Options are: gbdt, gbrt, rf (Random Forest), random_forest, dart (Dropouts meet Multiple Additive Regression Trees), goss (Gradient-based One-Side Sampling).  (default: gbdt)\n",
    "    categoricalSlotIndexes (list): List of categorical column indexes, the slot index in the features column (default: [I@1d15cacb)\n",
    "    categoricalSlotNames (list): List of categorical column slot names, the slot name in the features column (default: [Ljava.lang.String;@518b5988)\n",
    "    defaultListenPort (int): The default listen port on executors, used for testing (default: 12400)\n",
    "    driverListenPort (int): The listen port on a driver. Default value is 0 (random) (default: 0)\n",
    "    earlyStoppingRound (int): Early stopping round (default: 0)\n",
    "    featureFraction (double): Feature fraction (default: 1.0)\n",
    "    featuresCol (str): features column name (default: features)\n",
    "    featuresShapCol (str): Output SHAP vector column name after prediction containing the feature contribution values (default: )\n",
    "    improvementTolerance (double): Tolerance to consider improvement in metric (default: 0.0)\n",
    "    initScoreCol (str): The name of the initial score column, used for continued training\n",
    "    isProvideTrainingMetric (bool): Whether output metric result over training dataset. (default: false)\n",
    "    isUnbalance (bool): Set to true if training data is unbalanced in binary classification scenario (default: false)\n",
    "    labelCol (str): label column name (default: label)\n",
    "    lambdaL1 (double): L1 regularization (default: 0.0)\n",
    "    lambdaL2 (double): L2 regularization (default: 0.0)\n",
    "    leafPredictionCol (str): Predicted leaf indices's column name (default: )\n",
    "    learningRate (double): Learning rate or shrinkage rate (default: 0.1)\n",
    "    maxBin (int): Max bin (default: 255)\n",
    "    maxBinByFeature (list): Max number of bins for each feature (default: [I@3ca10949)\n",
    "    maxDeltaStep (double): Used to limit the max output of tree leaves (default: 0.0)\n",
    "    maxDepth (int): Max depth (default: -1)\n",
    "    metric (str): Metrics to be evaluated on the evaluation data.  Options are: empty string or not specified means that metric corresponding to specified objective will be used (this is possible only for pre-defined objective functions, otherwise no evaluation metric will be added). None (string, not a None value) means that no metric will be registered, aliases: na, null, custom. l1, absolute loss, aliases: mean_absolute_error, mae, regression_l1. l2, square loss, aliases: mean_squared_error, mse, regression_l2, regression. rmse, root square loss, aliases: root_mean_squared_error, l2_root. quantile, Quantile regression. mape, MAPE loss, aliases: mean_absolute_percentage_error. huber, Huber loss. fair, Fair loss. poisson, negative log-likelihood for Poisson regression. gamma, negative log-likelihood for Gamma regression. gamma_deviance, residual deviance for Gamma regression. tweedie, negative log-likelihood for Tweedie regression. ndcg, NDCG, aliases: lambdarank. map, MAP, aliases: mean_average_precision. auc, AUC. binary_logloss, log loss, aliases: binary. binary_error, for one sample: 0 for correct classification, 1 for error classification. multi_logloss, log loss for multi-class classification, aliases: multiclass, softmax, multiclassova, multiclass_ova, ova, ovr. multi_error, error rate for multi-class classification. cross_entropy, cross-entropy (with optional linear weights), aliases: xentropy. cross_entropy_lambda, intensity-weighted cross-entropy, aliases: xentlambda. kullback_leibler, Kullback-Leibler divergence, aliases: kldiv.  (default: )\n",
    "    minDataInLeaf (int): Minimal number of data in one leaf. Can be used to deal with over-fitting. (default: 20)\n",
    "    minGainToSplit (double): The minimal gain to perform split (default: 0.0)\n",
    "    minSumHessianInLeaf (double): Minimal sum hessian in one leaf (default: 0.001)\n",
    "    modelString (str): LightGBM model to retrain (default: )\n",
    "    negBaggingFraction (double): Negative Bagging fraction (default: 1.0)\n",
    "    numBatches (int): If greater than 0, splits data into separate batches during training (default: 0)\n",
    "    numIterations (int): Number of iterations, LightGBM constructs num_class * num_iterations trees (default: 100)\n",
    "    numLeaves (int): Number of leaves (default: 31)\n",
    "    numTasks (int): Advanced parameter to specify the number of tasks.  MMLSpark tries to guess this based on cluster configuration, but this parameter can be used to override. (default: 0)\n",
    "    objective (str): The Objective. For regression applications, this can be: regression_l2, regression_l1, huber, fair, poisson, quantile, mape, gamma or tweedie. For classification applications, this can be: binary, multiclass, or multiclassova.  (default: binary)\n",
    "    parallelism (str): Tree learner parallelism, can be set to data_parallel or voting_parallel (default: data_parallel)\n",
    "    posBaggingFraction (double): Positive Bagging fraction (default: 1.0)\n",
    "    predictionCol (str): prediction column name (default: prediction)\n",
    "    probabilityCol (str): Column name for predicted class conditional probabilities. Note: Not all models output well-calibrated probability estimates! These probabilities should be treated as confidences, not precise probabilities (default: probability)\n",
    "    rawPredictionCol (str): raw prediction (a.k.a. confidence) column name (default: rawPrediction)\n",
    "    repartitionByGroupingColumn (bool): Repartition training data according to grouping column, on by default. (default: true)\n",
    "    slotNames (list): List of slot names in the features column (default: [Ljava.lang.String;@17330338)\n",
    "    thresholds (list): Thresholds in multi-class classification to adjust the probability of predicting each class. Array must have length equal to the number of classes, with values > 0 excepting that at most one value may be 0. The class with largest value p/t is predicted, where p is the original probability of that class and t is the class's threshold\n",
    "    timeout (double): Timeout in seconds (default: 1200.0)\n",
    "    topK (int): The top_k value used in Voting parallel, set this to larger value for more accurate result, but it will slow down the training speed. It should be greater than 0 (default: 20)\n",
    "    useBarrierExecutionMode (bool): Use new barrier execution mode in Beta testing, off by default. (default: false)\n",
    "    validationIndicatorCol (str): Indicates whether the row is for training or validation\n",
    "    verbosity (int): Verbosity where lt 0 is Fatal, eq 0 is Error, eq 1 is Info, gt 1 is Debug (default: 1)\n",
    "    weightCol (str): The name of the weight column\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T22:55:28.872900Z",
     "start_time": "2020-08-26T22:55:23.986074Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Description</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rf</td>\n",
       "      <td>default</td>\n",
       "      <td>0.713372</td>\n",
       "      <td>0.691098</td>\n",
       "      <td>0.736099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lgb</td>\n",
       "      <td>default</td>\n",
       "      <td>0.718490</td>\n",
       "      <td>0.702969</td>\n",
       "      <td>0.724033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Description  Accuracy  Precision       AUC\n",
       "0    rf     default  0.713372   0.691098  0.736099\n",
       "1   lgb     default  0.718490   0.702969  0.724033"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mmlspark.lightgbm import LightGBMClassifier\n",
    "\n",
    "model = LightGBMClassifier(labelCol='affairs')\n",
    "\n",
    "# model.save('lgb.pkl')\n",
    "# model = LightGBMClassifier.load('lgb.pkl')\n",
    "\n",
    "model = model.fit(train)\n",
    "test_preds = model.transform(test)\n",
    "\n",
    "acc = MulticlassClassificationEvaluator(\n",
    "    labelCol='affairs',\n",
    "    metricName='accuracy'\n",
    "    ).evaluate(test_preds)\n",
    "\n",
    "precision = MulticlassClassificationEvaluator(\n",
    "    labelCol='affairs',\n",
    "    metricName='weightedPrecision'\n",
    "    ).evaluate(test_preds)\n",
    "\n",
    "auc = BinaryClassificationEvaluator(\n",
    "    labelCol='affairs'\n",
    "   ).evaluate(test_preds)\n",
    "\n",
    "\n",
    "row = [\"lgb\",'default',acc,precision,auc]\n",
    "df_eval.loc[len(df_eval)] = row\n",
    "df_eval = df_eval.drop_duplicates()\n",
    "df_eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T22:56:05.896456Z",
     "start_time": "2020-08-26T22:56:03.343747Z"
    }
   },
   "outputs": [],
   "source": [
    "from mmlspark.train import TrainClassifier\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "\n",
    "model = TrainClassifier(model=LogisticRegression(), labelCol=\"affairs\", numFeatures=256).fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T22:58:38.858781Z",
     "start_time": "2020-08-26T22:58:38.181736Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>evaluation_type</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Classification</td>\n",
       "      <td>DenseMatrix([[943., 128.],\\n             [323....</td>\n",
       "      <td>0.711452</td>\n",
       "      <td>0.569024</td>\n",
       "      <td>0.343496</td>\n",
       "      <td>0.744358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  evaluation_type                                   confusion_matrix  \\\n",
       "0  Classification  DenseMatrix([[943., 128.],\\n             [323....   \n",
       "\n",
       "   accuracy  precision    recall       AUC  \n",
       "0  0.711452   0.569024  0.343496  0.744358  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mmlspark.train import ComputeModelStatistics, TrainedClassifierModel\n",
    "\n",
    "prediction = model.transform(test)\n",
    "metrics = ComputeModelStatistics().transform(prediction)\n",
    "df_metrics = metrics.toPandas()\n",
    "\n",
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-26T22:59:06.173835Z",
     "start_time": "2020-08-26T22:59:06.166999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseMatrix(2, 2, [943.0, 323.0, 128.0, 169.0], False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics['confusion_matrix'][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Spark3",
   "language": "python",
   "name": "spk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
